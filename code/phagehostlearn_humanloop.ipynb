{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chronic-establishment",
   "metadata": {},
   "source": [
    "# PhageHostLearn - v3.3.klebsiella - human in the loop\n",
    "\n",
    "An AI-based Phage-Host interaction predictor framework with K-loci and receptor-binding proteins at its core. This particular PhageHostLearn is for *Klebsiella pneumoniae* related phages.\n",
    "\n",
    "This notebook offers the functionality to add new data to the PhageHostLearn framework and retrain the PhageHostLearn prediction models, without having to process all data from scratch. Here, it is assumed that you have completed the initial set-up that is carried out in the `phagehostlearn_training.ipynb`.\n",
    "\n",
    "**Overview of this notebook**\n",
    "- Setting A: new validated interactions for the same data\n",
    "- Setting B or C: new interactions for either new phages or bacteria (= new data)\n",
    "- Setting D: new interactions for new combinations of phages AND bacteria\n",
    "\n",
    "**Architecture of the PhageHostLearn framework**: \n",
    "- Multi-RBP setting: phages consisting of one or more RBPs (multi-instance)\n",
    "- K-loci proteins (multi-instance)\n",
    "- Embeddings for both based on ESM-2 language models and HDC\n",
    "- Combined XGBoost model (for language embeddings) and Random Forest (for HDC embeddings) to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7982b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "import phagehostlearn_utils as phlu\n",
    "import phagehostlearn_features as phlf\n",
    "import phagehostlearn_processing as phlp\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf11f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = '/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/42_DATA/Valencia_data'\n",
    "results_path = '/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models'\n",
    "data_suffix = 'Valencia'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe187e",
   "metadata": {},
   "source": [
    "## Setting A: adding validated interactions for the same data\n",
    "\n",
    "In this setting, we're not adding new phages or bacterial hosts, but we have tested new interactions for the phages and bacteria that are already present in the dataset. In this scenario, we only need to add those new interactions to our interaction matrix and retrain from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfae1a",
   "metadata": {},
   "source": [
    "#### A.1 Manually add the validated interactions in the .xlsx file with interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893891b",
   "metadata": {},
   "source": [
    "#### A.2 Reconstruct interaction matrix and feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_xlsx_path = general_path+'/klebsiella_phage_host_interactions.xlsx'\n",
    "phlp.process_interactions(general_path, interactions_xlsx_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb75f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_esm2, features_hdc, labels, groups_loci, groups_phage = phlf.construct_feature_matrices(general_path, \n",
    "                                                                                            data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a3c02",
   "metadata": {},
   "source": [
    "#### A.3 Retrain & save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ca0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus=6\n",
    "labels = np.asarray(labels)\n",
    "model_suffix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf64f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM-2 FEATURES + XGBoost model\n",
    "imbalance = sum([1 for i in labels if i==1]) / sum([1 for i in labels if i==0])\n",
    "xgb = XGBClassifier(scale_pos_weight=1/imbalance, learning_rate=0.2, n_estimators=250, max_depth=7,\n",
    "                    n_jobs=cpus, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb.fit(features_esm2, labels)\n",
    "xgb.save_model('phagehostlearn_esm2_xgb'+model_suffix+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec07c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDC FEATURES + RF model\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=5, class_weight='balanced', n_jobs=cpus)\n",
    "rf.fit(features_hdc, labels)\n",
    "dump(rf, 'phagehostlearn_hdc_rf'+model_suffix+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1d012",
   "metadata": {},
   "source": [
    "## Setting B/C: adding new phages or bacteria + interactions\n",
    "\n",
    "In this setting, we're adding either new phages or bacteria against the known bacteria or phages, respectively. This entails adding the new genomes.fasta files in the respective folders (see `phagehostlearn_training.ipynb`) and manually adding the new rows or columns to the interactions.xlsx file. Alternatively, you can make a new_interactions.xlsx file and combine it with the old interaction matrix in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77015918",
   "metadata": {},
   "source": [
    "#### BC.1 Manually add the new phage genomes or bacterial genomes to their designated folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229329aa",
   "metadata": {},
   "source": [
    "#### BC.2 Rerun the relevant processing steps with the add=True parameter\n",
    "\n",
    "If you've added new phage genomes, you'll have to rerun PHANOTATE, constructing protein embeddings and PhageRBPdetect. If you've added new bacterial genomes, you'll have to rerun Kaptive. Afterwards, rerun the processing of the interaction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHANOTATE\n",
    "phage_genomes_path = general_path+'/phages_genomes'\n",
    "phanotate_path = '/opt/homebrew/Caskroom/miniforge/base/envs/ML1/bin/phanotate.py'\n",
    "phlp.phanotate_processing(general_path, phage_genomes_path, phanotate_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62489ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein embeddings (alternatively run in Google Colab or Kaggle)\n",
    "phlp.compute_protein_embeddings(general_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhageRBPdetect\n",
    "pfam_path = general_path+'/RBPdetect_phageRBPs.hmm'\n",
    "hmmer_path = '/Users/Dimi/hmmer-3.3.1'\n",
    "xgb_path = general_path+'/RBPdetect_xgb_hmm.json'\n",
    "gene_embeddings_path = general_path+'/phage_protein_embeddings'+data_suffix+'.csv'\n",
    "phlp.phageRBPdetect(general_path, pfam_path, hmmer_path, xgb_path, gene_embeddings_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaptive\n",
    "bact_genomes_path = general_path+'/klebsiella_genomes/fasta_files'\n",
    "kaptive_database_path = general_path+'/Klebsiella_k_locus_primary_reference.gbk'\n",
    "phlp.process_bacterial_genomes(general_path, bact_genomes_path, kaptive_database_path, \n",
    "                               data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f18c5",
   "metadata": {},
   "source": [
    "#### BC.3 Manually add the new bacteria (as rows) or phages (as columns) and interactions in the interactions.xlsx Excel sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3c03d",
   "metadata": {},
   "source": [
    "#### BC.4 Reconstruct interaction matrix and feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff86e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_xlsx_path = general_path+'/klebsiella_phage_host_interactions.xlsx'\n",
    "phlp.process_interactions(general_path, interactions_xlsx_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ESM-2 RBP embeddings\n",
    "phlf.compute_esm2_embeddings_rbp(general_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ESM-2 loci embeddings\n",
    "phlf.compute_esm2_embeddings_loci(general_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03517b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute HDC embeddings\n",
    "locibase_path = general_path+'/Locibase'+data_suffix+'.json'\n",
    "rbpbase_path = general_path+'/RBPbase'+data_suffix+'.csv'\n",
    "phlf.compute_hdc_embedding(general_path, data_suffix, locibase_path, rbpbase_path, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0855d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_esm2, features_hdc, labels, groups_loci, groups_phage = phlf.construct_feature_matrices(general_path, \n",
    "                                                                                            data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25c8b7",
   "metadata": {},
   "source": [
    "#### BC.5 Retrain and save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = 6\n",
    "labels = np.asarray(labels)\n",
    "model_suffix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM-2 FEATURES + XGBoost model\n",
    "imbalance = sum([1 for i in labels if i==1]) / sum([1 for i in labels if i==0])\n",
    "xgb = XGBClassifier(scale_pos_weight=1/imbalance, learning_rate=0.2, n_estimators=250, max_depth=7,\n",
    "                    n_jobs=cpus, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb.fit(features_esm2, labels)\n",
    "xgb.save_model('phagehostlearn_esm2_xgb'+model_suffix+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c62b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDC FEATURES + RF model\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=5, class_weight='balanced', n_jobs=cpus)\n",
    "rf.fit(features_hdc, labels)\n",
    "dump(rf, 'phagehostlearn_hdc_rf'+model_suffix+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3149f2",
   "metadata": {},
   "source": [
    "## Setting D: adding new phages AND bacteria + interactions\n",
    "\n",
    "In this setting, you're adding interactions for new combinations of phages AND bacteria. Here, we will incorporate these new interactions from a new .xlsx file containing the interactions, and then rerun all the processing steps with the add=True argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e689f",
   "metadata": {},
   "source": [
    "#### D.1 Manually add the new phage genomes and bacterial genomes to their designated folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462b755",
   "metadata": {},
   "source": [
    "#### D.2 Make a new .xlsx file for the new interactions with the bactrerial accession in the first column (each row a new bacterium) and the phage names in the first row (each column a new phage). Store the .xlsx file in the general folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388f58b",
   "metadata": {},
   "source": [
    "#### D.3 Rerun all the processing steps with add=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3de244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHANOTATE\n",
    "phage_genomes_path = general_path+'/phages_genomes'\n",
    "phanotate_path = '/opt/homebrew/Caskroom/miniforge/base/envs/ML1/bin/phanotate.py'\n",
    "phlp.phanotate_processing(general_path, phage_genomes_path, phanotate_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein embeddings (alternatively run in Google Colab or Kaggle)\n",
    "phlp.compute_protein_embeddings(general_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhageRBPdetect\n",
    "pfam_path = general_path+'/RBPdetect_phageRBPs.hmm'\n",
    "hmmer_path = '/Users/Dimi/hmmer-3.3.1'\n",
    "xgb_path = general_path+'/RBPdetect_xgb_hmm.json'\n",
    "gene_embeddings_path = general_path+'/phage_protein_embeddings'+data_suffix+'.csv'\n",
    "phlp.phageRBPdetect(general_path, pfam_path, hmmer_path, xgb_path, gene_embeddings_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaptive\n",
    "bact_genomes_path = general_path+'/klebsiella_genomes/fasta_files'\n",
    "kaptive_database_path = general_path+'/Klebsiella_k_locus_primary_reference.gbk'\n",
    "phlp.process_bacterial_genomes(general_path, bact_genomes_path, kaptive_database_path, \n",
    "                               data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214147f",
   "metadata": {},
   "source": [
    "#### D.4 Integrate the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_interactions_xlsx_path = general_path+'/klebsiella_phage_host_interactions.xlsx'\n",
    "new_interactions_xlsx_path = ...\n",
    "interactions_path = general_path+'/phage_host_interactions'+data_suffix\n",
    "phlp.process_interactions(general_path, original_interactions_xlsx_path, data_suffix=data_suffix)\n",
    "phlp.add_to_database(interactions_path+'.csv', new_interactions_xlsx_path, interactions_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c76b9",
   "metadata": {},
   "source": [
    "#### D.5 Reconstruct features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ESM-2 RBP embeddings\n",
    "phlf.compute_esm2_embeddings_rbp(general_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ESM-2 loci embeddings\n",
    "phlf.compute_esm2_embeddings_loci(general_path, data_suffix=data_suffix, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute HDC embeddings\n",
    "locibase_path = general_path+'/Locibase'+data_suffix+'.json'\n",
    "rbpbase_path = general_path+'/RBPbase'+data_suffix+'.csv'\n",
    "phlf.compute_hdc_embedding(general_path, data_suffix, locibase_path, rbpbase_path, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_esm2, features_hdc, labels, groups_loci, groups_phage = phlf.construct_feature_matrices(general_path, \n",
    "                                                                                            data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a93a4",
   "metadata": {},
   "source": [
    "#### D.6 Retrain and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c655cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = 6\n",
    "labels = np.asarray(labels)\n",
    "model_suffix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead91f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM-2 FEATURES + XGBoost model\n",
    "imbalance = sum([1 for i in labels if i==1]) / sum([1 for i in labels if i==0])\n",
    "xgb = XGBClassifier(scale_pos_weight=1/imbalance, learning_rate=0.2, n_estimators=250, max_depth=7,\n",
    "                    n_jobs=cpus, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb.fit(features_esm2, labels)\n",
    "xgb.save_model('phagehostlearn_esm2_xgb'+model_suffix+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52041e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDC FEATURES + RF model\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=5, class_weight='balanced', n_jobs=cpus)\n",
    "rf.fit(features_hdc, labels)\n",
    "dump(rf, 'phagehostlearn_hdc_rf'+model_suffix+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83b57a",
   "metadata": {},
   "source": [
    "## 4. Training and evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416719a1",
   "metadata": {},
   "source": [
    "#### 4.1 Training both models and saving them for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "344d28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus=6\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "647d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM-2 FEATURES + XGBoost model\n",
    "imbalance = sum([1 for i in labels if i==1]) / sum([1 for i in labels if i==0])\n",
    "xgb = XGBClassifier(scale_pos_weight=1/imbalance, learning_rate=0.2, n_estimators=250, max_depth=7,\n",
    "                    n_jobs=cpus, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb.fit(features_esm2, labels)\n",
    "xgb.save_model('phagehostlearn_esm2_xgb.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa979503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phagehostlearn_hdc_rf.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HDC FEATURES + RF model\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=5, class_weight='balanced', n_jobs=cpus)\n",
    "rf.fit(features_hdc, labels)\n",
    "dump(rf, 'phagehostlearn_hdc_rf.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cdf400e2b2cf645b2ec6a448fcb5b3c1b3d3d5834714944466c9c0370880fa51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
