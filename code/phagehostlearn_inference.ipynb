{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chronic-establishment",
   "metadata": {},
   "source": [
    "# PhageHostLearn - v3.3.klebsiella - inference\n",
    "\n",
    "An AI-based Phage-Host interaction predictor framework with K-loci and receptor-binding proteins at its core. This particular PhageHostLearn is for *Klebsiella pneumoniae* related phages. \n",
    "\n",
    "This notebook offers complete functionality to train a PhageHostLearn prediction model for Klebsiella phages starting from phage genomes, bacterial genomes and a matrix of known interactions.\n",
    "\n",
    "**Overview of this notebook**\n",
    "1. Initial set-up\n",
    "2. Processing phage genomes and bacterial genomes into RBPs and K-locus proteins, respectively\n",
    "3. Computing feature representations based on ESM-2 and Hyperdimensional computing\n",
    "4. Predicting new interactions and ranking\n",
    "\n",
    "**Architecture of the PhageHostLearn framework**: \n",
    "- Multi-RBP setting: phages consisting of one or more RBPs (multi-instance)\n",
    "- K-loci proteins (multi-instance) \n",
    "- Embeddings for both based on ESM-2 language models and HDC\n",
    "- Combined XGBoost model (for language embeddings) and Random Forest (for HDC embeddings) to make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97849c",
   "metadata": {},
   "source": [
    "## 1. Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf6121",
   "metadata": {},
   "source": [
    "PhageHostLearn takes as inputs phage genomes and bacterial genomes that are later transformed into phage RBPs and bacterial K-locus proteins. To do this data processing, you'll need to do the following:\n",
    "1. Set up a TEST folder for all the test data that will be stored and generated by PhageHostLearn. Write the path to this folder in the code block below for 'test_path'. The 'general_path' is the path to the training data as it is used in the `phagehostlearn_training.ipynb` notebook.\n",
    "2. In the TEST folder, create one or two subfolders for the new phage genomes and/or bacterial genomes to test (one for phage genomes and one for bacterial genomes if you have both). Collect both phage genomes and bacterial genomes as individual FASTA files and store them in the two separate folders. You can also make predictions for either new bacteria or new phages against the training set, in that case you only need to create one subfolder.\n",
    "3. Install [PHANOTATE](https://github.com/deprekate/PHANOTATE) and [Kaptive](https://github.com/katholt/Kaptive), both of which you'll need to process the phage and bacterial genomes. Locate PHANOTATE and write the path under the 2.1 code block below. **can be simplified by copying PHANOTATE into code folder?** From the Kaptive repository, copy the .gbk databases into the general data folder.\n",
    "4. Optionally install [bio_embeddings](https://github.com/sacdallago/bio_embeddings) to locally compute protein embeddings needed for RBP detection or opt do do this step in the cloud for faster results (see instructions below).\n",
    "5. Install [fair-esm](https://github.com/facebookresearch/esm) to compute ESM-2 embeddings for the PhageHostLearn interaction prediction models.\n",
    "6. Install [Julia](https://julialang.org) to compute hyperdimensional embeddings for the PhageHostLearn interaction prediction models. **extra info on packages etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf11f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/42_DATA/inference'\n",
    "test_suffix = '_test'\n",
    "general_path = '/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/42_DATA/Valencia_data'\n",
    "general_suffix = 'Valencia'\n",
    "results_path = '/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60092310",
   "metadata": {},
   "source": [
    "## 2. Data processing\n",
    "\n",
    "The data processing of PhageHostLearn consists of four consecutive steps: (1) phage gene calling with PHANOTATE, (2) phage protein embedding with bio_embeddings, (3) phage RBP detection and (4) bacterial genome processing with Kaptive.\n",
    "\n",
    "- Test new phages against the bacteria in the training set: only run the processing steps for the phage genomes (2.1-2.3)\n",
    "- Test new bacteria against the phages in the training set: only run the processing steps for the bacterial genomes (2.4)\n",
    "- Test combinations of new phages and new bacteria: run all the processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc090f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phagehostlearn_processing as phlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b686db",
   "metadata": {},
   "source": [
    "#### 2.1 PHANOTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d633972",
   "metadata": {},
   "outputs": [],
   "source": [
    "phage_genomes_path = test_path+'/phages_genomes'\n",
    "phanotate_path = '/opt/homebrew/Caskroom/miniforge/base/envs/ML1/bin/phanotate.py'\n",
    "phlp.phanotate_processing(test_path, phage_genomes_path, phanotate_path, data_suffix=test_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a48369",
   "metadata": {},
   "source": [
    "#### 2.2 Protein embeddings\n",
    "\n",
    "The code block below computes protein embeddings for all of the detected phage genes (translated to proteins) using the bio_embeddings package (see Initial set-up). This might take a while on CPU. Alternatively, you can run this step in Google Colab or on Kaggle using the 'compute_embeddings_cloud.ipynb', which does exactly the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62489ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phlp.compute_protein_embeddings(test_path, data_suffix=test_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07fe07",
   "metadata": {},
   "source": [
    "#### 2.3 PhageRBPdetect\n",
    "\n",
    "Either copy the `RBPdetect_phageRBPs.hmm` and `RBPdetect_xgb_hmm.json` files into the general data folder, or provide their absolute paths in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam_path = test_path+'/RBPdetect_phageRBPs.hmm'\n",
    "hmmer_path = '/Users/Dimi/hmmer-3.3.1'\n",
    "xgb_path = test_path+'/RBPdetect_xgb_hmm.json'\n",
    "gene_embeddings_path = test_path+'/phage_protein_embeddings'+test_suffix+'.csv'\n",
    "phlp.phageRBPdetect(test_path, pfam_path, hmmer_path, xgb_path, gene_embeddings_path, data_suffix=test_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed4b0c",
   "metadata": {},
   "source": [
    "#### 2.4 Kaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be319ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57057b9cabd44d7d97d85d397a00e875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bact_genomes_path = test_path+'/bacterial_genomes'\n",
    "kaptive_database_path = general_path+'/Klebsiella_k_locus_primary_reference.gbk'\n",
    "#kaptive_path = '/Users/dimi/Documents/GitHub/PhageHostLearning/processing'\n",
    "phlp.process_bacterial_genomes(test_path, bact_genomes_path, kaptive_database_path, '', data_suffix=test_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13771b",
   "metadata": {},
   "source": [
    "## 3. Feature construction\n",
    "\n",
    "Starts from the RBPbase.csv and the Locibase.json in the general_path. The last function outputs two feature matrices (ESM-2 and HDC), labels, groups_loci and groups_phage (for evaluation). If the ESM-2 embeddings take too long, you might opt to do this step in the cloud or on a high-performance computer.\n",
    "\n",
    "If you're retraining a model with the same data but new validated interactions, you can simply run the `construct_feature_matrices` function to construct updated feature matrices and labels and train models anew. If you've also added new phage or bacterial genomes, you need to rerun all of the processing steps as well (only for the new data **work in progress**).\n",
    "\n",
    "- Test new phages against the bacteria in the training set: only run the feature steps for the phage (3.1, 3.3, 3.4). Set the correct paths to Locibase_train, RBPbase_test and the embeddings!\n",
    "- Test new bacteria against the phages in the training set: only run the feature steps for the bacteria (3.2, 3.3, 3.4). Set the correct paths to Locibase_test, RBPbase_train and the embeddings!\n",
    "- Test combinations of new phages and new bacteria: run all the feature steps and set the paths to Locibase_test, RBPbase_test and the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be94f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phagehostlearn_features as phlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1beeb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "locibase_path = test_path+'/Locibase'+test_suffix+'.json'\n",
    "rbpbase_path = general_path+'/RBPbase'+general_suffix+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4dfcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_embeddings_path = general_path+'/esm2_embeddings_rbp'+general_suffix+'.csv'\n",
    "loci_embeddings_path = test_path+'/esm2_embeddings_loci'+test_suffix+'.csv'\n",
    "hdc_embeddings_path = test_path+'/hdc_features'+test_suffix+'.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9591",
   "metadata": {},
   "source": [
    "#### 3.1 ESM-2 RBP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34687caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phlf.compute_esm2_embeddings_rbp(test_path, data_suffix=test_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb63b5",
   "metadata": {},
   "source": [
    "#### 3.2 ESM-2 loci features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94526a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [01:12<00:00, 72.80s/it]\n"
     ]
    }
   ],
   "source": [
    "phlf.compute_esm2_embeddings_loci(test_path, data_suffix=test_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa2431",
   "metadata": {},
   "source": [
    "#### 3.3 HDC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbbcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "phlf.compute_hdc_embedding(test_path, test_suffix, locibase_path, rbpbase_path, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ee064",
   "metadata": {},
   "source": [
    "#### 3.4 Construct feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d25edb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match? True\n",
      "Dimensions match? True\n"
     ]
    }
   ],
   "source": [
    "features_esm2, features_hdc, groups_bact = phlf.construct_feature_matrices(general_path, general_suffix, loci_embeddings_path, \n",
    "                                                             rbp_embeddings_path, hdc_embeddings_path, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83b57a",
   "metadata": {},
   "source": [
    "## 4. Predict and rank new interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f6b84",
   "metadata": {},
   "source": [
    "What we want is to make predictions per bacterium for all of the phages, and then use the prediction scores to rank the potential phages per bacterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "drawn-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phagehostlearn_utils as phlu\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from joblib import dump, load\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut, GroupShuffleSplit, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996ea2d",
   "metadata": {},
   "source": [
    "#### 4.1 Make predictions with trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "344d28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM-2 FEATURES + XGBoost model\n",
    "xgb = XGBClassifier()\n",
    "xgb.load_model('phagehostlearn_esm2_xgb.json')\n",
    "scores_xgb = xgb.predict_proba(features_esm2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8616d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDC FEATURES + RF model\n",
    "rf = load('phagehostlearn_hdc_rf.joblib')\n",
    "scores_rf = rf.predict_proba(features_hdc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b6fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scores with uninorm operator\n",
    "scores = np.asarray([phlu.uninorm(scores_rf[j], scores_xgb[j]) for j in range(len(scores_xgb))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ba138",
   "metadata": {},
   "source": [
    "#### 4.2 Save predictions as a matrix and ranked list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction scores in an interaction matrix\n",
    "groups_bact = np.asarray(groups_bact)\n",
    "loci_embeddings = pd.read_csv(loci_embeddings_path)\n",
    "rbp_embeddings = pd.read_csv(rbp_embeddings_path)\n",
    "bacteria = list(loci_embeddings['accession'])\n",
    "phages = list(set(rbp_embeddings['phage_ID']))\n",
    "\n",
    "score_matrix = np.zeros((len(bacteria), len(phages)))\n",
    "for i, group in enumerate(list(set(groups_bact))):\n",
    "    scores_this_group = scores[groups_bact == group]\n",
    "    score_matrix[i, :] = scores_this_group\n",
    "results = pd.DataFrame(score_matrix, index=bacteria, columns=phages)\n",
    "results.to_csv(results_path+'/prediction_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bebc6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank the phages per bacterium\n",
    "ranked = {}\n",
    "for group in list(set(groups_bact)):\n",
    "    scores_this_group = scores[groups_bact == group]\n",
    "    ranked_phages = [x for _, x in sorted(zip(scores_this_group, phages), reverse=True)]\n",
    "    ranked[bacteria[group]] = ranked_phages\n",
    "ranked_results = pd.DataFrame(ranked)\n",
    "ranked_results.to_csv(results_path+'/ranked_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
