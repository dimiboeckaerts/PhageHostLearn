{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f577d7df",
   "metadata": {},
   "source": [
    "# PhageHostLearn - v2.2 (Klebsiella)\n",
    "\n",
    "An AI-based Phage-Host interaction predictor framework with K-loci and receptor-binding proteins at its core. This particular PhageHostLearn is for *Klebsiella pneumoniae* related phages. This notebook follows after having ran the PhageHostLearn_processing steps implemented in the accompanying Jupyter notebook.\n",
    "\n",
    "**Architecture of this framework**: \n",
    "- Multi-RBP setting: phages consisting of one or more RBPs (multi-instance)\n",
    "- K-loci proteins (multi-instance) \n",
    "- Hyperdimensional vector embeddings for both that are bound or concatenated\n",
    "- HDC learning of both classes of labels by aggregation\n",
    "- Cosine similarity to compute interacting phage-host pairs\n",
    "\n",
    "**Overview of the notebook**:\n",
    "\n",
    "1. [Defining the necessary functions](#functions)\n",
    "2. [Transform the loci sequences into embeddings](#lociembed) using hyperdimensional vectors\n",
    "3. [Transform the RBP sequences into embeddings](#rbpembed) using hyperdimensional vectors\n",
    "4. [Compute joint features: bind or concat](#joint)\n",
    "5. [Aggregation and cosine similarity](#hdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc1380",
   "metadata": {},
   "source": [
    "## 0 - Libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3e26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using MLJ\n",
    "using Test\n",
    "using JSON\n",
    "using Plots\n",
    "using FASTX\n",
    "using MLBase\n",
    "using Colors\n",
    "using Random\n",
    "using XGBoost\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using BioAlignments\n",
    "using ProgressMeter\n",
    "using LinearAlgebra\n",
    "using ProgressMeter\n",
    "using BioAlignments\n",
    "using DelimitedFiles\n",
    "using MultivariateStats\n",
    "using ScikitLearn.Pipelines: Pipeline\n",
    "using ScikitLearn.CrossValidation: train_test_split \n",
    "using ScikitLearn.GridSearch: GridSearchCV\n",
    "using ScikitLearn.Skcore: make_scorer\n",
    "\n",
    "@sk_import decomposition: PCA\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import metrics: roc_auc_score\n",
    "\n",
    "push!(LOAD_PATH, \"/Users/dimi/Documents/GitHub/HyperdimensionalComputing.jl/src/\")\n",
    "using HyperdimensionalComputing\n",
    "\n",
    "general_dir = \"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/42_DATA/Valencia_data\" # general directory\n",
    "results_dir = \"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models\"\n",
    "data_suffix = \"Valencia\"; # choose a suffix for the created data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cff52b",
   "metadata": {},
   "source": [
    "## 1 - Functions<a name=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015ad564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function file_to_array(file)\n",
    "    \"\"\"\n",
    "    Function that reads a FASTA file and puts its sequences in an array.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    reader = FASTA.Reader(open(file, \"r\"))\n",
    "    for record in reader\n",
    "        seq = FASTA.sequence(record)\n",
    "        push!(sequences, seq)\n",
    "    end\n",
    "    return sequences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc871105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_reciprocal_rank (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean_reciprocal_rank(queries)\n",
    "    \"\"\"\n",
    "    This function computes the mean reciprocal rank for a given array or\n",
    "    matrix of queries. It deals with relevant vs. non-relevant queries that are\n",
    "    binary. If queries is a matrix, then it will compute the reciprocal ranks over\n",
    "    all rows individually (for each 'query') and then average those.\n",
    "    E.g.:\n",
    "    queries = [[0, 0, 0], [0, 1, 0], [1, 0, 0]]\n",
    "    mean_reciprocal_rank(queries) -> 0.5\n",
    "    \"\"\"\n",
    "    if isa(queries, Matrix)\n",
    "        queries_list = [queries[i,:] for i in 1:size(queries)[1]]\n",
    "        reciprocal_ranks = [sum(query) > 0 ? 1/argmax(query) : 0 for query in queries_list]\n",
    "    else\n",
    "        reciprocal_ranks = [sum(query) > 0 ? 1/argmax(query) : 0 for query in queries]\n",
    "    end\n",
    "    return mean(reciprocal_ranks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3be05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sort_label_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sort_label_matrix(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function sorts the label matrix based on the score matrix.\n",
    "    It does so per row (corresponding to bacteria in our setting).\n",
    "    \n",
    "    WARNING: The sortperm function will rank equal elements by ascending index order. \n",
    "    This potentially can cause an underestimation of performance (MRR), as it can be that \n",
    "    an irrelevant 0 appears earlier and then is place before a relevant 1.\n",
    "    \"\"\"\n",
    "    @assert size(label_matrix) == size(score_matrix)\n",
    "    sorted_matrix = zeros(Int64, size(label_matrix)[1], size(label_matrix)[2])\n",
    "    for i in 1:size(label_matrix)[1] # loop over rows\n",
    "        label_row = label_matrix[i,:]\n",
    "        score_row = score_matrix[i,:]\n",
    "        sorted_row = label_row[sortperm(score_row, rev=true)]\n",
    "        sorted_matrix[i,:] = sorted_row\n",
    "    end\n",
    "    return sorted_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596df09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mrr_from_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mrr_from_scores(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function is a wrapper for the previous functions that computes\n",
    "    the MRR starting from a matrix of (prediction) scores, a threshold above\n",
    "    which to consider an interaction positive and a label matrix.\n",
    "    \"\"\"\n",
    "    # sort the matrix per row and compute\n",
    "    replace!(label_matrix, missing => 0)\n",
    "    sorted_matrix = sort_label_matrix(score_matrix, label_matrix)\n",
    "    \n",
    "    return mean_reciprocal_rank(sorted_matrix)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916c4a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc_from_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function auc_from_scores(scores_flat, labels_flat)\n",
    "    \"\"\"\n",
    "    This function computes the AUC from raw scores returned by ScikitLearn classifiers.\n",
    "    For the AUC, we need the flat versions of scores and labels that don't contain missing \n",
    "    values (if not, this will skew the results).\n",
    "    \n",
    "    Dependencies: MLJ\n",
    "    \"\"\"\n",
    "    c = [\"neg\", \"pos\"]\n",
    "    labels_cat = categorical(c[labels_flat .+ 1])\n",
    "    scores_uni = [UnivariateFinite(categorical([\"neg\", \"pos\"]), [1.0 - p, p]) for p in scores_flat]\n",
    "    AUC = auc(scores_uni, labels_cat)\n",
    "    return AUC\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7123b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_performance (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_performance(score_matrix, label_matrix, scores_flat, labels_flat)\n",
    "    \"\"\"\n",
    "    Wrapper function that computes the two relevant results we want to compare for \n",
    "    our models: the ROC AUC and the MRR.    \n",
    "    \"\"\"\n",
    "    MRR = mrr_from_scores(score_matrix, label_matrix) # compute MRR\n",
    "    AUC = auc_from_scores(scores_flat, labels_flat) # compute AUC\n",
    "    return MRR, AUC\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db0834",
   "metadata": {},
   "source": [
    "## 2 - Computing loci embeddings<a name=\"lociembed\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dcb22",
   "metadata": {},
   "source": [
    "In this section, we define hyperdimensional vectors for the amino-acid alphabet and use these hyperdimensional vectors to construct *hyperdimensional embeddings* for our loci proteins. For the loci proteins, this is a multi-instance setting: multiple proteins will be embedded into hyperdimensional space and then those vectors are aggregated to form one final vector for each locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69da2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "LociBase = JSON.parsefile(general_dir*\"/Locibase\"*data_suffix*\".json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb78964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define protein alphabet\n",
    "alphabet = \"GAVLIFPSTYCMKRHWDENQX\"\n",
    "basis = Dict(c=>BipolarHDV() for c in alphabet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "356e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loci embeddings w/ proteins (multi-instance)\n",
    "loci_embeddings = Array{BipolarHDV}(undef, length(LociBase))\n",
    "for (i, (name, proteins)) in enumerate(LociBase)\n",
    "    # bind within one sequence, then aggregate the different sequences\n",
    "    protein_hdvs = [sequence_embedding(string(sequence), basis, 6) for sequence in proteins]\n",
    "    loci_hdv = HyperdimensionalComputing.aggregate(protein_hdvs)\n",
    "    loci_embeddings[i] = loci_hdv\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573ebc0",
   "metadata": {},
   "source": [
    "## 3 - Computing RBP embeddings<a name=\"rbpembed\"></a>\n",
    "\n",
    "We combine the vectors for each phage's RBP(s), also a multi-instance setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b646f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "RBPbase = DataFrame(CSV.File(general_dir*\"/RBPbase\"*data_suffix*\".csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982319c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rbp embeddings\n",
    "rbp_embeddings = Array{BipolarHDV}(undef, length(unique(RBPbase.phage_ID)))\n",
    "for (i, phageid) in enumerate(unique(RBPbase.phage_ID))\n",
    "    subset = filter(row -> row.phage_ID == phageid, RBPbase)\n",
    "    protein_hdvs = [sequence_embedding(string(sequence), basis, 6) for sequence in subset.protein_sequence]\n",
    "    multirbp_hdv = HyperdimensionalComputing.aggregate(protein_hdvs)\n",
    "    rbp_embeddings[i] = multirbp_hdv\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46957e",
   "metadata": {},
   "source": [
    "## 4 - Compute joint feature representations and make dataframe for training<a name=\"joint\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71dbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = DataFrame(CSV.File(general_dir*\"/phage_host_interactions\"*data_suffix*\".csv\"))\n",
    "rename!(IM,:Column1 => :Host)\n",
    "interaction_matrix = Matrix(IM[1:end, 2:end])\n",
    "#loci_names = IM.accession\n",
    "#serotypes = DataFrame(CSV.File(general_dir*\"/serotypes\"*data_suffix*\".csv\"))\n",
    "#rbp_names = names(IM)[2:end];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58156925",
   "metadata": {},
   "source": [
    "##### Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb21946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sigatures for loci x RBP embeddings\n",
    "features_bind = []\n",
    "labels = []\n",
    "for (i, accession) in enumerate(collect(keys(LociBase)))\n",
    "    for (j, phage_id) in enumerate(unique(RBPbase.phage_ID))\n",
    "        subset = filter(row -> row.Host == accession, IM)\n",
    "        interaction = subset[!, phage_id][1]\n",
    "        if isequal(interaction, 1) || isequal(interaction, 0)\n",
    "            signature = HyperdimensionalComputing.bind([loci_embeddings[i], rbp_embeddings[j]])\n",
    "            push!(features_bind, signature)\n",
    "            push!(labels, trunc(Int, interaction))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c70737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the signatures in a matrix for sklearn\n",
    "features_b = zeros(Int64, length(features_bind), 10000)\n",
    "for i in range(1, length=length(features_bind))\n",
    "    features_b[i,:] = features_bind[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7377488",
   "metadata": {},
   "source": [
    "#### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c25d9706",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: \u001b[0mCannot `convert` an object of type \u001b[92mInt64\u001b[39m\u001b[0m to an object of type \u001b[91mBipolarHDV\u001b[39m\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::Factorization\u001b[39m) where T<:AbstractArray at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/factorization.jl:58\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T<:AbstractArray at abstractarray.jl:14\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at essentials.jl:205\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: \u001b[0mCannot `convert` an object of type \u001b[92mInt64\u001b[39m\u001b[0m to an object of type \u001b[91mBipolarHDV\u001b[39m\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::Factorization\u001b[39m) where T<:AbstractArray at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/factorization.jl:58\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T<:AbstractArray at abstractarray.jl:14\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at essentials.jl:205\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      "  [1] setindex!(A::Vector{BipolarHDV}, x::Int64, i1::Int64)",
      "    @ Base ./array.jl:843",
      "  [2] _unsafe_copyto!(dest::Vector{BipolarHDV}, doffs::Int64, src::Vector{Int64}, soffs::Int64, n::Int64)",
      "    @ Base ./array.jl:235",
      "  [3] unsafe_copyto!",
      "    @ ./array.jl:289 [inlined]",
      "  [4] _copyto_impl!",
      "    @ ./array.jl:313 [inlined]",
      "  [5] copyto!",
      "    @ ./array.jl:299 [inlined]",
      "  [6] copyto!",
      "    @ ./array.jl:325 [inlined]",
      "  [7] copyto_axcheck!",
      "    @ ./abstractarray.jl:1056 [inlined]",
      "  [8] Vector{BipolarHDV}(x::Vector{Int64})",
      "    @ Base ./array.jl:540",
      "  [9] convert(#unused#::Type{Vector{BipolarHDV}}, a::Vector{Int64})",
      "    @ Base ./array.jl:532",
      " [10] top-level scope",
      "    @ In[63]:10",
      " [11] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [12] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# compute [loci] + [RBP] embeddings\n",
    "features_concat = []\n",
    "labels = []\n",
    "for (i, accession) in enumerate(collect(keys(LociBase)))\n",
    "    for (j, phage_id) in enumerate(unique(RBPbase.phage_ID))\n",
    "        subset = filter(row -> row.Host == accession, IM)\n",
    "        interaction = subset[!, phage_id][1]\n",
    "        if isequal(interaction, 1) || isequal(interaction, 0)\n",
    "            concatenation = vcat(loci_embeddings[i], rbp_embeddings[j])\n",
    "            push!(features_concat, convert(Array{BipolarHDV}, concatenation))\n",
    "            push!(labels, trunc(Int, interaction))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633832b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the signatures in a matrix for sklearn\n",
    "features_c = zeros(Int64, length(features_concat), 20000)\n",
    "for i in range(1, length=length(features_concat))\n",
    "    features_c[i,:] = features_concat[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4e0e8",
   "metadata": {},
   "source": [
    "## 6 - HDC learning<a name=\"hdc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7f5e5",
   "metadata": {},
   "source": [
    "##### Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59bba8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform K-fold cross-validation and keep the scores\n",
    "scores = []\n",
    "scores_pos = []\n",
    "kfold_labels = []\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=5, shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = features_bind[train_indices]\n",
    "    y_train = labels[train_indices]\n",
    "    x_test = features_bind[test_indices]\n",
    "    y_test = labels[test_indices]\n",
    "    \n",
    "    # train aggregates\n",
    "    # centers = train(y_train, x_train)\n",
    "    positives = convert(Array{BipolarHDV}, x_train[y_train .== 1])\n",
    "    negatives = convert(Array{BipolarHDV}, x_train[y_train .== 0])\n",
    "    pos_aggregate = HyperdimensionalComputing.aggregate(positives)\n",
    "    neg_aggregate = HyperdimensionalComputing.aggregate(negatives)\n",
    "    \n",
    "    # compute similarities\n",
    "    for (i, test) in enumerate(x_test)\n",
    "        score_pos = cos_sim(pos_aggregate, test) + 1 # add one to scale between 0 and 2 (BIPOLAR VECTORS!)\n",
    "        score_neg = cos_sim(neg_aggregate, test) + 1\n",
    "        push!(scores, score_pos/score_neg) # > 1 then pos, < 1 then neg\n",
    "        push!(scores_pos, score_pos/2) # divide by two to scale between 0 and 1\n",
    "        push!(kfold_labels, y_test[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f5e50ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445154697904913"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(kfold_labels, scores_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e183c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models/v2.2/hdc_bind_cosine_scores.csv\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save scores for plotting\n",
    "results = DataFrame(labels=kfold_labels, scores=scores_pos)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_bind_cosine_scores.csv\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e4ebc",
   "metadata": {},
   "source": [
    "We see quite a good AUC score for the scores_pos (only comparing to the positive aggregate), however all the scores are very close to 0.5 (which unscaled would be a cossim = 0) -> but isn't that logical as we are binding in high-dimensional spaces? As you bind, you make something that is almost independent to any other thing in the space, so makes sense that all cosinesims are around 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde3d2fd",
   "metadata": {},
   "source": [
    "##### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6f0f1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304-element Vector{BipolarHDV}:\n",
       " [-1, -1, -1, 1, 1, 0, -1, 1, -1, 1  …  -1, -1, 0, 1, -1, 1, -1, 1, -1, 0]\n",
       " [0, 0, 0, -1, -1, 0, -1, 0, 0, 1  …  1, 0, 1, 0, 0, 0, -1, -1, 1, 0]\n",
       " [0, 1, 0, 0, 0, 0, -1, 0, 1, -1  …  -1, 0, 0, 0, 0, 1, 0, -1, 0, 0]\n",
       " [-1, 0, 1, 1, 0, 0, -1, 0, 1, -1  …  0, -1, 0, -1, 1, -1, 1, 0, 1, 1]\n",
       " [0, -1, 1, -1, 1, 0, -1, 1, -1, -1  …  0, -1, 1, 1, 1, 1, 1, 1, 1, -1]\n",
       " [0, -1, -1, -1, -1, 0, -1, -1, -1, 1  …  0, 1, -1, -1, -1, 1, -1, 0, -1, 0]\n",
       " [0, -1, 0, -1, -1, 0, 0, 0, -1, -1  …  0, 0, 0, 0, -1, 0, 0, 0, -1, 1]\n",
       " [1, 0, 0, 0, 0, 1, 0, 1, 0, 0  …  0, -1, 0, -1, 0, -1, 0, -1, 0, 0]\n",
       " [1, 1, 1, 1, -1, 0, -1, -1, 0, -1  …  -1, 1, -1, 0, 0, 1, -1, 0, 0, -1]\n",
       " [0, 0, 0, 0, 0, -1, -1, -1, 0, 1  …  0, 1, 1, 0, -1, 0, 0, 1, 0, -1]\n",
       " [1, -1, -1, 1, 0, 0, -1, -1, 1, 0  …  -1, 1, 1, -1, 0, 0, -1, -1, 0, 0]\n",
       " [-1, -1, 1, 1, 1, -1, -1, -1, -1, -1  …  0, 1, -1, -1, -1, -1, -1, 0, -1, 0]\n",
       " [1, 1, 1, -1, 0, 0, 1, -1, 1, 0  …  0, 1, 1, -1, 0, 1, -1, -1, 0, 0]\n",
       " ⋮\n",
       " [-1, 0, 0, -1, 1, 1, 0, -1, 0, 0  …  0, 0, 0, -1, 0, 1, 1, 1, 0, 0]\n",
       " [1, 0, 1, 1, 1, -1, -1, -1, 1, -1  …  0, -1, -1, 1, -1, -1, -1, 1, 1, -1]\n",
       " [-1, 0, -1, -1, 0, 1, -1, -1, 1, 0  …  0, -1, -1, 1, 1, 1, -1, -1, 1, 1]\n",
       " [-1, -1, -1, -1, -1, 1, 1, 1, 1, 1  …  -1, -1, 1, 1, 0, -1, 1, 1, -1, 1]\n",
       " [-1, 0, 0, 1, -1, 1, 0, -1, 0, 0  …  0, 0, 0, -1, 0, 1, 1, 1, 0, 0]\n",
       " [-1, 0, -1, -1, -1, -1, 0, 1, -1, -1  …  0, 0, 0, 0, 0, -1, -1, 1, 0, 1]\n",
       " [1, -1, -1, -1, -1, -1, -1, -1, 1, 1  …  -1, -1, 1, 1, 0, -1, -1, 1, -1, 1]\n",
       " [0, -1, 0, 0, -1, -1, 1, 0, 0, 1  …  0, -1, 0, -1, 0, 0, 0, 1, -1, 1]\n",
       " [1, 1, -1, -1, -1, 1, 1, -1, 1, 1  …  -1, 1, 1, 1, 0, -1, -1, 1, -1, -1]\n",
       " [-1, -1, -1, 1, 1, 1, 1, -1, 1, 1  …  1, 1, 1, -1, 0, -1, 1, -1, -1, -1]\n",
       " [1, 1, -1, -1, -1, -1, -1, 1, -1, 1  …  -1, -1, -1, -1, 0, 1, 1, 1, 1, 1]\n",
       " [-1, 1, 1, 1, 0, 1, -1, -1, 1, 0  …  1, -1, 1, 1, 0, 1, -1, -1, -1, -1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = convert(Array{BipolarHDV}, features_bind[labels .== 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de0f30d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: \u001b[0mCannot `convert` an object of type \u001b[92mVector{Int64}\u001b[39m\u001b[0m to an object of type \u001b[91mBipolarHDV\u001b[39m\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::Factorization\u001b[39m) where T<:AbstractArray at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/factorization.jl:58\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T<:AbstractArray at abstractarray.jl:14\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at essentials.jl:205\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: \u001b[0mCannot `convert` an object of type \u001b[92mVector{Int64}\u001b[39m\u001b[0m to an object of type \u001b[91mBipolarHDV\u001b[39m\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::Factorization\u001b[39m) where T<:AbstractArray at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/LinearAlgebra/src/factorization.jl:58\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T<:AbstractArray at abstractarray.jl:14\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at essentials.jl:205\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      "  [1] setindex!(A::Vector{BipolarHDV}, x::Vector{Int64}, i1::Int64)",
      "    @ Base ./array.jl:843",
      "  [2] _unsafe_copyto!(dest::Vector{BipolarHDV}, doffs::Int64, src::Vector{Any}, soffs::Int64, n::Int64)",
      "    @ Base ./array.jl:235",
      "  [3] unsafe_copyto!",
      "    @ ./array.jl:289 [inlined]",
      "  [4] _copyto_impl!",
      "    @ ./array.jl:313 [inlined]",
      "  [5] copyto!",
      "    @ ./array.jl:299 [inlined]",
      "  [6] copyto!",
      "    @ ./array.jl:325 [inlined]",
      "  [7] copyto_axcheck!",
      "    @ ./abstractarray.jl:1056 [inlined]",
      "  [8] Vector{BipolarHDV}(x::Vector{Any})",
      "    @ Base ./array.jl:540",
      "  [9] Array",
      "    @ ./boot.jl:473 [inlined]",
      " [10] convert(#unused#::Type{Array{BipolarHDV, N} where N}, a::Vector{Any})",
      "    @ Base ./array.jl:532",
      " [11] top-level scope",
      "    @ ./In[52]:14",
      " [12] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# perform K-fold cross-validation and keep the scores\n",
    "scores = []\n",
    "scores_pos = []\n",
    "kfold_labels = []\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=5, shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = features_concat[train_indices]\n",
    "    y_train = labels[train_indices]\n",
    "    x_test = features_concat[test_indices]\n",
    "    y_test = labels[test_indices]\n",
    "    \n",
    "    # train aggregates\n",
    "    # centers = train(y_train, x_train)\n",
    "    positives = convert(Array{BipolarHDV}, x_train[y_train .== 1])\n",
    "    negatives = convert(Array{BipolarHDV}, x_train[y_train .== 0])\n",
    "    pos_aggregate = HyperdimensionalComputing.aggregate(positives)\n",
    "    neg_aggregate = HyperdimensionalComputing.aggregate(negatives)\n",
    "    \n",
    "    # compute similarities\n",
    "    for (i, test) in enumerate(x_test)\n",
    "        score_pos = cos_sim(pos_aggregate, test) + 1 # add one to scale between 0 and 2 (BIPOLAR VECTORS!)\n",
    "        score_neg = cos_sim(neg_aggregate, test) + 1\n",
    "        push!(scores, score_pos/score_neg) # > 1 then pos, < 1 then neg\n",
    "        push!(scores_pos, score_pos/2) # divide by two to scale between 0 and 1\n",
    "        push!(kfold_labels, y_test[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97aca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(kfold_labels, scores_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scores for plotting\n",
    "results = DataFrame(labels=kfold_labels, scores=scores_pos)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_concat_cosine_scores.csv\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d22a3",
   "metadata": {},
   "source": [
    "#### b) HDC model that considers both positive and negative aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a08705b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the cross-validation and keep the scores\n",
    "#similarities = Dict()\n",
    "similarities = zeros(Float64, length(loci_embeddings), length(rbp_embeddings))\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=10, \n",
    "        shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = signatures[train_indices]\n",
    "    y_train = labels[train_indices]\n",
    "    x_test = signatures[test_indices]\n",
    "    y_test = labels[test_indices]\n",
    "    \n",
    "    # train the aggregates\n",
    "    centers = train(y_train, x_train)\n",
    "    \n",
    "    # compute ratio of similarities to aggregates (centers[0] -> neg-, centers[1] -> pos+) and keep the index\n",
    "    similarities_k = [cos_sim(centers[1], x)/cos_sim(centers[0], x) for x in x_test]\n",
    "    for (i, test_i) in enumerate(test_indices)\n",
    "        pos_i, pos_j = positions[test_i][1], positions[test_i][2]\n",
    "        similarities[pos_i, pos_j] = similarities_k[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4a388",
   "metadata": {},
   "source": [
    "But this isn't really satisfactory because if the sim scores to pos aggregate are negative, things shift from interpretation (the higher the ratio the closer to pos+ aggregate will not hold anymore... check notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c863bed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1394852301398791"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_from_scores(similarities, interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205933e6",
   "metadata": {},
   "source": [
    "## X - Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10452d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary: | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for MRR | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for MRR\" begin\n",
    "    @test mean_reciprocal_rank([[0, 0, 0], [0, 1, 0], [1, 0, 0]]) == 0.5\n",
    "    @test mean_reciprocal_rank([[1, 0, 0], [1, 1, 0], [1, 0, 0]]) == 1\n",
    "    A = [0 0 0; 0 1 0; 1 0 0] # Matrix\n",
    "    @test mean_reciprocal_rank(A) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77d726c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:                          | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for constructing relevant matrix | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for constructing relevant matrix\" begin\n",
    "    preds = [0 0 1; 1 1 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == labels # all TPs\n",
    "    preds = [0 0 0; 1 0 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 0; 1 0 0; 0 0 0] # missed TPs\n",
    "    preds = [0 1 0; 1 1 0; 1 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 0; 1 1 0; 0 0 0] # FPs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ecf63855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:                  | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for sorting label matrix | \u001b[32m   2  \u001b[39m\u001b[36m    2\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for sorting label matrix\" begin \n",
    "    rel = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0.5 0.3 1; 1 0.3 0.7; 0.2 0.3 0.3]\n",
    "    @test sort_label_matrix(scores, rel) == [1 0 0; 1 0 1; 0 0 0]\n",
    "    \n",
    "    rel = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [1 0.3 1; 1 0.3 0.7; 0.2 0.3 0.3] # equal score for 0 and 1\n",
    "    @test sort_label_matrix(scores, rel) == [0 1 0; 1 0 1; 0 0 0] # equals will appear in ascending order\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "522f6870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:  | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests pipeline | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests pipeline\" begin\n",
    "    preds = [0 0 1; 0 1 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0 0.2 0.5; 0.3 0.2 0.1; 0.2 0.4 0.3]\n",
    "    relm = construct_relevant_matrix(preds, labels)\n",
    "    sortm = sort_label_matrix(scores, relm)\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 1; 0 1 0; 0 0 0]\n",
    "    @test sort_relevant_matrix(relm, scores) == [1 0 0; 0 1 0; 0 0 0] \n",
    "    @test mean_reciprocal_rank(sortm) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01358f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:         | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests mrr from scores | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests mrr from scores\" begin\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0 0.2 0.5; 0.3 0.5 0.6; 0.2 0.4 0.3]\n",
    "    @test mrr_from_scores(scores, labels, 0.4) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143556f7",
   "metadata": {},
   "source": [
    "## X - Legacy code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee06006",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Here, we perform a 10-fold CV over the loci, just like we do to evaluate the\n",
    "binary classifiers in Python.\n",
    "\"\"\"\n",
    "loci_known = [x for x in range(1, length=length(LociBase)) \n",
    "                if (any(isequal.(interaction_matrix[x,:], 0))) \n",
    "                    || (any(isequal.(interaction_matrix[x,:], 1)))]\n",
    "\n",
    "# shuffle loci\n",
    "loci_shuffle = shuffle(loci_known)\n",
    "\n",
    "# divide into 10 groups\n",
    "group_size = div(length(loci_shuffle), 10) + 1\n",
    "get_groups(x, n) = [x[i:min(i+n-1,length(x))] for i in 1:n:length(x)]\n",
    "loci_groups = get_groups(loci_shuffle, group_size)\n",
    "\n",
    "# loop over groups\n",
    "loci_nr = []; rbp_nr = []; scores = []; scores_pos = []; labels = []\n",
    "for group in loci_groups\n",
    "    # compute signatures for training and testing parts (group = test)\n",
    "    signatures_train_pos = []\n",
    "    signatures_train_neg = []\n",
    "    signatures_test = []\n",
    "    for (i, loci_embedding) in enumerate(loci_embeddings)\n",
    "        for (j, rbp_embedding) in enumerate(rbp_embeddings)\n",
    "            # training pos interaction\n",
    "            if isequal(interaction_matrix[i,j], 1) && i ∉ group\n",
    "                push!(signatures_train_pos, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "            # training neg interaction\n",
    "            elseif isequal(interaction_matrix[i,j], 0) && i ∉ group\n",
    "                push!(signatures_train_neg, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "            # test interaction\n",
    "            elseif isequal(interaction_matrix[i,j], 1) && i in group\n",
    "                push!(signatures_test, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "                push!(loci_nr, i-1) # -1 to cope with indexing python\n",
    "                push!(rbp_nr, j-1)\n",
    "                push!(labels, interaction_matrix[i,j])\n",
    "            elseif isequal(interaction_matrix[i,j], 0) && i in group\n",
    "                push!(signatures_test, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "                push!(loci_nr, i-1)\n",
    "                push!(rbp_nr, j-1)\n",
    "                push!(labels, interaction_matrix[i,j])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # convert signatures\n",
    "    signatures_train_pos = convert(Array{BipolarHDV}, signatures_train_pos)\n",
    "    signatures_train_neg = convert(Array{BipolarHDV}, signatures_train_neg)\n",
    "    signatures_test = convert(Array{BipolarHDV}, signatures_test)\n",
    "    println(\"train size:\", length(signatures_train_pos)+length(signatures_train_neg))\n",
    "    println(\"test size:\", length(signatures_test))\n",
    "    \n",
    "    # aggregate training signatures\n",
    "    signatures_pos_agg = HyperdimensionalComputing.aggregate(signatures_train_pos)\n",
    "    signatures_neg_agg = HyperdimensionalComputing.aggregate(signatures_train_neg)\n",
    "\n",
    "    # compute distance/similarity to test signatures\n",
    "    for test in signatures_test\n",
    "        score_pos_agg = cos_sim(signatures_pos_agg, test)\n",
    "        score_neg_agg = cos_sim(signatures_neg_agg, test)\n",
    "        push!(scores, score_pos_agg/score_neg_agg) # > 1 then pos, < 1 then neg\n",
    "        push!(scores_pos, score_pos_agg)\n",
    "    end\n",
    "end\n",
    "\n",
    "# results pos vs. neg\n",
    "results = DataFrame(locus=loci_nr, rbps=rbp_nr, scores=scores, label=labels)\n",
    "CSV.write(results_dir*\"/results_HDC_grouped10CV_\"*data_suffix*\".csv\", results)\n",
    "\n",
    "# results pos only\n",
    "results = DataFrame(locus=loci_nr, rbps=rbp_nr, scores=scores_pos, label=labels)\n",
    "CSV.write(results_dir*\"/results_HDCpos_grouped10CV_\"*data_suffix*\".csv\", results)\n",
    "\n",
    "# examine scores\n",
    "histogram(scores, xlabel=\"score\", ylabel=\"count\")\n",
    "sum(scores .< 1)/length(scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "226146c2",
   "metadata": {},
   "source": [
    "function construct_relevant_matrix(preds_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function constructs a matrix of relevant predictions\n",
    "    (i.e., true positives) from the prediction matrix and label matrix.\n",
    "    \"\"\"\n",
    "    @assert size(preds_matrix) == size(label_matrix)\n",
    "    relevant_matrix = zeros(Int64, size(preds_matrix)[1], size(preds_matrix)[2])\n",
    "    for i in 1:size(preds_matrix)[1]\n",
    "        for j in 1:size(preds_matrix)[2]\n",
    "            if (preds_matrix[i,j] == label_matrix[i,j]) & (label_matrix[i,j] == 1)\n",
    "                relevant_matrix[i,j] = 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return relevant_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "085a9cd7",
   "metadata": {},
   "source": [
    "function mrr_from_scores_OLD(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    OLD version of the function is a wrapper for the previous functions that computes\n",
    "    the MRR starting from a matrix of (prediction) scores, a threshold above\n",
    "    which to consider an interaction positive and a label matrix.\n",
    "    \"\"\"\n",
    "    # construct the prediction matrix\n",
    "    preds_matrix = convert(Matrix{Int64}, score_matrix .> threshold)\n",
    "\n",
    "    # construct the relevant matrix\n",
    "    replace!(label_matrix, missing => 0)\n",
    "    rel_matrix = construct_relevant_matrix(preds_matrix, label_matrix)\n",
    "\n",
    "    # sort the matrix per row and compute\n",
    "    sorted_matrix = sort_relevant_matrix(rel_matrix, score_matrix)\n",
    "    \n",
    "    return mean_reciprocal_rank(sorted_matrix)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
