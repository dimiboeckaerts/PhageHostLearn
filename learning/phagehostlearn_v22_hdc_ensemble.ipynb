{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f577d7df",
   "metadata": {},
   "source": [
    "# PhageHostLearn - v2.2 (Klebsiella)\n",
    "\n",
    "An AI-based Phage-Host interaction predictor framework with K-loci and receptor-binding proteins at its core. This particular PhageHostLearn is for *Klebsiella pneumoniae* related phages. This notebook follows after having ran the PhageHostLearn_processing steps implemented in the accompanying Jupyter notebook.\n",
    "\n",
    "**Architecture of this framework**: \n",
    "- Multi-RBP setting: phages consisting of one or more RBPs (multi-instance)\n",
    "- K-loci proteins (multi-instance) \n",
    "- Hyperdimensional vector embeddings for both that are bound or concatenated\n",
    "- Do PCA and train an XGBoost and RF model on the reduced embeddings (binary classification)\n",
    "\n",
    "**Overview of the notebook**:\n",
    "\n",
    "1. [Defining the necessary functions](#functions)\n",
    "2. [Transform the loci sequences into embeddings](#lociembed) using hyperdimensional vectors\n",
    "3. [Transform the RBP sequences into embeddings](#rbpembed) using hyperdimensional vectors\n",
    "4. [Compute joint features: bind or concat](#joint)\n",
    "5. [PCA and RF](#machinelearning)\n",
    "5. [Exploration of the embeddings](#explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc1380",
   "metadata": {},
   "source": [
    "## 0 - Libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3e26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using MLJ\n",
    "using Test\n",
    "using JSON\n",
    "using Plots\n",
    "using FASTX\n",
    "using MLBase\n",
    "using Colors\n",
    "using Random\n",
    "using XGBoost\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using BioAlignments\n",
    "using ProgressMeter\n",
    "using LinearAlgebra\n",
    "using ProgressMeter\n",
    "using BioAlignments\n",
    "using DelimitedFiles\n",
    "using MultivariateStats\n",
    "using ScikitLearn.Pipelines: Pipeline\n",
    "using ScikitLearn.CrossValidation: train_test_split \n",
    "using ScikitLearn.GridSearch: GridSearchCV\n",
    "using ScikitLearn.Skcore: make_scorer\n",
    "\n",
    "@sk_import decomposition: PCA\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import metrics: roc_auc_score\n",
    "\n",
    "push!(LOAD_PATH, \"/Users/dimi/Documents/GitHub/HyperdimensionalComputing.jl/src/\")\n",
    "using HyperdimensionalComputing\n",
    "\n",
    "general_dir = \"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/42_DATA/Valencia_data\" # general directory\n",
    "results_dir = \"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models\"\n",
    "data_suffix = \"Valencia\"; # choose a suffix for the created data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cff52b",
   "metadata": {},
   "source": [
    "## 1 - Functions<a name=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015ad564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function file_to_array(file)\n",
    "    \"\"\"\n",
    "    Function that reads a FASTA file and puts its sequences in an array.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    reader = FASTA.Reader(open(file, \"r\"))\n",
    "    for record in reader\n",
    "        seq = FASTA.sequence(record)\n",
    "        push!(sequences, seq)\n",
    "    end\n",
    "    return sequences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc871105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_reciprocal_rank (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean_reciprocal_rank(queries)\n",
    "    \"\"\"\n",
    "    This function computes the mean reciprocal rank for a given array or\n",
    "    matrix of queries. It deals with relevant vs. non-relevant queries that are\n",
    "    binary. If queries is a matrix, then it will compute the reciprocal ranks over\n",
    "    all rows individually (for each 'query') and then average those.\n",
    "    E.g.:\n",
    "    queries = [[0, 0, 0], [0, 1, 0], [1, 0, 0]]\n",
    "    mean_reciprocal_rank(queries) -> 0.5\n",
    "    \"\"\"\n",
    "    if isa(queries, Matrix)\n",
    "        queries_list = [queries[i,:] for i in 1:size(queries)[1]]\n",
    "        reciprocal_ranks = [sum(query) > 0 ? 1/argmax(query) : 0 for query in queries_list]\n",
    "    else\n",
    "        reciprocal_ranks = [sum(query) > 0 ? 1/argmax(query) : 0 for query in queries]\n",
    "    end\n",
    "    return mean(reciprocal_ranks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3be05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sort_label_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sort_label_matrix(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function sorts the label matrix based on the score matrix.\n",
    "    It does so per row (corresponding to bacteria in our setting).\n",
    "    \n",
    "    WARNING: The sortperm function will rank equal elements by ascending index order. \n",
    "    This potentially can cause an underestimation of performance (MRR), as it can be that \n",
    "    an irrelevant 0 appears earlier and then is place before a relevant 1.\n",
    "    \"\"\"\n",
    "    @assert size(label_matrix) == size(score_matrix)\n",
    "    sorted_matrix = zeros(Int64, size(label_matrix)[1], size(label_matrix)[2])\n",
    "    for i in 1:size(label_matrix)[1] # loop over rows\n",
    "        label_row = label_matrix[i,:]\n",
    "        score_row = score_matrix[i,:]\n",
    "        sorted_row = label_row[sortperm(score_row, rev=true)]\n",
    "        sorted_matrix[i,:] = sorted_row\n",
    "    end\n",
    "    return sorted_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596df09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mrr_from_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mrr_from_scores(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function is a wrapper for the previous functions that computes\n",
    "    the MRR starting from a matrix of (prediction) scores, a threshold above\n",
    "    which to consider an interaction positive and a label matrix.\n",
    "    \"\"\"\n",
    "    # sort the matrix per row and compute\n",
    "    replace!(label_matrix, missing => 0)\n",
    "    sorted_matrix = sort_label_matrix(score_matrix, label_matrix)\n",
    "    \n",
    "    return mean_reciprocal_rank(sorted_matrix)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916c4a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc_from_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function auc_from_scores(scores_flat, labels_flat)\n",
    "    \"\"\"\n",
    "    This function computes the AUC from raw scores returned by ScikitLearn classifiers.\n",
    "    For the AUC, we need the flat versions of scores and labels that don't contain missing \n",
    "    values (if not, this will skew the results).\n",
    "    \n",
    "    Dependencies: MLJ\n",
    "    \"\"\"\n",
    "    c = [\"neg\", \"pos\"]\n",
    "    labels_cat = categorical(c[labels_flat .+ 1])\n",
    "    scores_uni = [UnivariateFinite(categorical([\"neg\", \"pos\"]), [1.0 - p, p]) for p in scores_flat]\n",
    "    AUC = auc(scores_uni, labels_cat)\n",
    "    return AUC\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7123b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_performance (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_performance(score_matrix, label_matrix, scores_flat, labels_flat)\n",
    "    \"\"\"\n",
    "    Wrapper function that computes the two relevant results we want to compare for \n",
    "    our models: the ROC AUC and the MRR.    \n",
    "    \"\"\"\n",
    "    MRR = mrr_from_scores(score_matrix, label_matrix) # compute MRR\n",
    "    AUC = auc_from_scores(scores_flat, labels_flat) # compute AUC\n",
    "    return MRR, AUC\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db0834",
   "metadata": {},
   "source": [
    "## 2 - Computing loci embeddings<a name=\"lociembed\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dcb22",
   "metadata": {},
   "source": [
    "In this section, we define hyperdimensional vectors for the amino-acid alphabet and use these hyperdimensional vectors to construct *hyperdimensional embeddings* for our loci proteins. For the loci proteins, this is a multi-instance setting: multiple proteins will be embedded into hyperdimensional space and then those vectors are aggregated to form one final vector for each locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69da2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "LociBase = JSON.parsefile(general_dir*\"/Locibase\"*data_suffix*\".json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb78964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define protein alphabet\n",
    "alphabet = \"GAVLIFPSTYCMKRHWDENQX\"\n",
    "basis = Dict(c=>BipolarHDV() for c in alphabet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "356e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loci embeddings w/ proteins (multi-instance)\n",
    "loci_embeddings = Array{BipolarHDV}(undef, length(LociBase))\n",
    "for (i, (name, proteins)) in enumerate(LociBase)\n",
    "    # bind within one sequence, then aggregate the different sequences\n",
    "    protein_hdvs = [sequence_embedding(string(sequence), basis, 6) for sequence in proteins]\n",
    "    loci_hdv = HyperdimensionalComputing.aggregate(protein_hdvs)\n",
    "    loci_embeddings[i] = loci_hdv\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573ebc0",
   "metadata": {},
   "source": [
    "## 3 - Computing RBP embeddings<a name=\"rbpembed\"></a>\n",
    "\n",
    "We combine the vectors for each phage's RBP(s), also a multi-instance setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b646f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "RBPbase = DataFrame(CSV.File(general_dir*\"/RBPbase\"*data_suffix*\".csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982319c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rbp embeddings\n",
    "rbp_embeddings = Array{BipolarHDV}(undef, length(unique(RBPbase.phage_ID)))\n",
    "for (i, phageid) in enumerate(unique(RBPbase.phage_ID))\n",
    "    subset = filter(row -> row.phage_ID == phageid, RBPbase)\n",
    "    protein_hdvs = [sequence_embedding(string(sequence), basis, 6) for sequence in subset.protein_sequence]\n",
    "    multirbp_hdv = HyperdimensionalComputing.aggregate(protein_hdvs)\n",
    "    rbp_embeddings[i] = multirbp_hdv\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46957e",
   "metadata": {},
   "source": [
    "## 4 - Compute joint feature representations and make dataframe for training<a name=\"joint\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71dbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = DataFrame(CSV.File(general_dir*\"/phage_host_interactions\"*data_suffix*\".csv\"))\n",
    "rename!(IM,:Column1 => :Host)\n",
    "interaction_matrix = Matrix(IM[1:end, 2:end])\n",
    "#loci_names = IM.accession\n",
    "#serotypes = DataFrame(CSV.File(general_dir*\"/serotypes\"*data_suffix*\".csv\"))\n",
    "#rbp_names = names(IM)[2:end];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58156925",
   "metadata": {},
   "source": [
    "##### Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb21946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sigatures for loci x RBP embeddings\n",
    "features_bind = []\n",
    "labels = []\n",
    "for (i, accession) in enumerate(collect(keys(LociBase)))\n",
    "    for (j, phage_id) in enumerate(unique(RBPbase.phage_ID))\n",
    "        subset = filter(row -> row.Host == accession, IM)\n",
    "        interaction = subset[!, phage_id][1]\n",
    "        if isequal(interaction, 1) || isequal(interaction, 0)\n",
    "            signature = HyperdimensionalComputing.bind([loci_embeddings[i], rbp_embeddings[j]])\n",
    "            push!(features_bind, signature)\n",
    "            push!(labels, trunc(Int, interaction))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c70737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the signatures in a matrix for sklearn\n",
    "features_b = zeros(Int64, length(features_bind), 10000)\n",
    "for i in range(1, length=length(features_bind))\n",
    "    features_b[i,:] = features_bind[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7377488",
   "metadata": {},
   "source": [
    "#### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25d9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute [loci] + [RBP] embeddings\n",
    "features_concat = []\n",
    "labels = []\n",
    "for (i, accession) in enumerate(collect(keys(LociBase)))\n",
    "    for (j, phage_id) in enumerate(unique(RBPbase.phage_ID))\n",
    "        subset = filter(row -> row.Host == accession, IM)\n",
    "        interaction = subset[!, phage_id][1]\n",
    "        if isequal(interaction, 1) || isequal(interaction, 0)\n",
    "            concatenation = vcat(loci_embeddings[i], rbp_embeddings[j])\n",
    "            push!(features_concat, concatenation)\n",
    "            push!(labels, trunc(Int, interaction))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633832b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the signatures in a matrix for sklearn\n",
    "features_c = zeros(Int64, length(features_concat), 20000)\n",
    "for i in range(1, length=length(features_concat))\n",
    "    features_c[i,:] = features_concat[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4aa51",
   "metadata": {},
   "source": [
    "## 5 - Do PCA and build RF model<a name=\"machinelearning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe932b",
   "metadata": {},
   "source": [
    "##### Binding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb2e38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and set test set aside\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_b, labels, test_size=0.2, stratify=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d44377ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and CV\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "pca = PCA()\n",
    "pipe = Pipeline([(\"pca\", pca), (\"rf\", rf)])\n",
    "params_pipe = Dict(\"pca__n_components\"=>[50, 100, 200, 300], \"rf__n_estimators\"=>[100, 250, 500, 750])\n",
    "cv = CrossValidation.StratifiedKFold(y_train, n_folds=5, shuffle=true, random_state=42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do hyperparameter tuning\n",
    "rocauc = make_scorer(roc_auc_score)\n",
    "xgb_tuned = GridSearchCV(pipe, params_pipe, cv=cv, scoring=rocauc, verbose=3)\n",
    "ScikitLearn.fit!(xgb_tuned, X_train, y_train)\n",
    "println(xgb_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a683ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482508205335837"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set evaluation\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\")\n",
    "pca = PCA(n_components=200)\n",
    "pipe = Pipeline([(\"pca\", pca), (\"rf\", rf)])\n",
    "model = ScikitLearn.fit!(pipe, X_train, y_train)\n",
    "scores_pos = ScikitLearn.predict_proba(model, X_test)[:,2]\n",
    "roc_auc_score(y_test, scores_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41f62a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models/v2.2/hdc_bind_rf_scores.csv\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save scores for plotting\n",
    "results = DataFrame(labels=y_test, scores=scores_pos)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_bind_rf_scores.csv\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bd8d1",
   "metadata": {},
   "source": [
    "##### Concatenating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fd6e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and set test set aside\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_b, labels, test_size=0.2, stratify=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed3e5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and CV\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "pca = PCA()\n",
    "pipe = Pipeline([(\"pca\", pca), (\"rf\", rf)])\n",
    "params_pipe = Dict(\"pca__n_components\"=>[50, 100, 200, 300], \"rf__n_estimators\"=>[100, 250, 500, 750])\n",
    "cv = CrossValidation.StratifiedKFold(y_train, n_folds=5, shuffle=true, random_state=42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8cf26717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] rf__n_estimators=100, pca__n_components=50\n",
      "[CV] rf__n_estimators=100, pca__n_components=50, score=0.63925  -  5.0s\n",
      "[CV] rf__n_estimators=100, pca__n_components=50\n",
      "[CV] rf__n_estimators=100, pca__n_components=50, score=0.59941  -  4.9s\n",
      "[CV] rf__n_estimators=100, pca__n_components=50\n",
      "[CV] rf__n_estimators=100, pca__n_components=50, score=0.61982  -  4.8s\n",
      "[CV] rf__n_estimators=100, pca__n_components=50\n",
      "[CV] rf__n_estimators=100, pca__n_components=50, score=0.61163  -  4.7s\n",
      "[CV] rf__n_estimators=100, pca__n_components=50\n",
      "[CV] rf__n_estimators=100, pca__n_components=50, score=0.68454  -  4.9s\n",
      "[CV] rf__n_estimators=250, pca__n_components=50\n",
      "[CV] rf__n_estimators=250, pca__n_components=50, score=0.63925  -  7.5s\n",
      "[CV] rf__n_estimators=250, pca__n_components=50\n",
      "[CV] rf__n_estimators=250, pca__n_components=50, score=0.59941  -  7.3s\n",
      "[CV] rf__n_estimators=250, pca__n_components=50\n",
      "[CV] rf__n_estimators=250, pca__n_components=50, score=0.63068  -  7.5s\n",
      "[CV] rf__n_estimators=250, pca__n_components=50\n",
      "[CV] rf__n_estimators=250, pca__n_components=50, score=0.61163  -  7.3s\n",
      "[CV] rf__n_estimators=250, pca__n_components=50\n",
      "[CV] rf__n_estimators=250, pca__n_components=50, score=0.69496  -  7.5s\n",
      "[CV] rf__n_estimators=500, pca__n_components=50\n",
      "[CV] rf__n_estimators=500, pca__n_components=50, score=0.63925  -  11.7s\n",
      "[CV] rf__n_estimators=500, pca__n_components=50\n",
      "[CV] rf__n_estimators=500, pca__n_components=50, score=0.58921  -  11.8s\n",
      "[CV] rf__n_estimators=500, pca__n_components=50\n",
      "[CV] rf__n_estimators=500, pca__n_components=50, score=0.63101  -  11.7s\n",
      "[CV] rf__n_estimators=500, pca__n_components=50\n",
      "[CV] rf__n_estimators=500, pca__n_components=50, score=0.62204  -  11.9s\n",
      "[CV] rf__n_estimators=500, pca__n_components=50\n",
      "[CV] rf__n_estimators=500, pca__n_components=50, score=0.67413  -  11.8s\n",
      "[CV] rf__n_estimators=750, pca__n_components=50\n",
      "[CV] rf__n_estimators=750, pca__n_components=50, score=0.63925  -  16.1s\n",
      "[CV] rf__n_estimators=750, pca__n_components=50\n",
      "[CV] rf__n_estimators=750, pca__n_components=50, score=0.58888  -  15.9s\n",
      "[CV] rf__n_estimators=750, pca__n_components=50\n",
      "[CV] rf__n_estimators=750, pca__n_components=50, score=0.63068  -  16.2s\n",
      "[CV] rf__n_estimators=750, pca__n_components=50\n",
      "[CV] rf__n_estimators=750, pca__n_components=50, score=0.61163  -  15.8s\n",
      "[CV] rf__n_estimators=750, pca__n_components=50\n",
      "[CV] rf__n_estimators=750, pca__n_components=50, score=0.68454  -  16.4s\n",
      "[CV] rf__n_estimators=100, pca__n_components=100\n",
      "[CV] rf__n_estimators=100, pca__n_components=100, score=0.63925  -  7.3s\n",
      "[CV] rf__n_estimators=100, pca__n_components=100\n",
      "[CV] rf__n_estimators=100, pca__n_components=100, score=0.63003  -  7.5s\n",
      "[CV] rf__n_estimators=100, pca__n_components=100\n",
      "[CV] rf__n_estimators=100, pca__n_components=100, score=0.65142  -  7.3s\n",
      "[CV] rf__n_estimators=100, pca__n_components=100\n",
      "[CV] rf__n_estimators=100, pca__n_components=100, score=0.61163  -  7.6s\n",
      "[CV] rf__n_estimators=100, pca__n_components=100\n",
      "[CV] rf__n_estimators=100, pca__n_components=100, score=0.68454  -  7.6s\n",
      "[CV] rf__n_estimators=250, pca__n_components=100\n",
      "[CV] rf__n_estimators=250, pca__n_components=100, score=0.63925  -  11.4s\n",
      "[CV] rf__n_estimators=250, pca__n_components=100\n",
      "[CV] rf__n_estimators=250, pca__n_components=100, score=0.63003  -  11.2s\n",
      "[CV] rf__n_estimators=250, pca__n_components=100\n",
      "[CV] rf__n_estimators=250, pca__n_components=100, score=0.66162  -  11.2s\n",
      "[CV] rf__n_estimators=250, pca__n_components=100\n",
      "[CV] rf__n_estimators=250, pca__n_components=100, score=0.61163  -  11.9s\n",
      "[CV] rf__n_estimators=250, pca__n_components=100\n",
      "[CV] rf__n_estimators=250, pca__n_components=100, score=0.68454  -  12.4s\n",
      "[CV] rf__n_estimators=500, pca__n_components=100\n",
      "[CV] rf__n_estimators=500, pca__n_components=100, score=0.63925  -  17.5s\n",
      "[CV] rf__n_estimators=500, pca__n_components=100\n",
      "[CV] rf__n_estimators=500, pca__n_components=100, score=0.63003  -  19.4s\n",
      "[CV] rf__n_estimators=500, pca__n_components=100\n",
      "[CV] rf__n_estimators=500, pca__n_components=100, score=0.65142  -  17.6s\n",
      "[CV] rf__n_estimators=500, pca__n_components=100\n",
      "[CV] rf__n_estimators=500, pca__n_components=100, score=0.61163  -  17.8s\n",
      "[CV] rf__n_estimators=500, pca__n_components=100\n",
      "[CV] rf__n_estimators=500, pca__n_components=100, score=0.68454  -  17.8s\n",
      "[CV] rf__n_estimators=750, pca__n_components=100\n",
      "[CV] rf__n_estimators=750, pca__n_components=100, score=0.63925  -  24.5s\n",
      "[CV] rf__n_estimators=750, pca__n_components=100\n",
      "[CV] rf__n_estimators=750, pca__n_components=100, score=0.63003  -  24.0s\n",
      "[CV] rf__n_estimators=750, pca__n_components=100\n",
      "[CV] rf__n_estimators=750, pca__n_components=100, score=0.66162  -  23.2s\n",
      "[CV] rf__n_estimators=750, pca__n_components=100\n",
      "[CV] rf__n_estimators=750, pca__n_components=100, score=0.61163  -  23.7s\n",
      "[CV] rf__n_estimators=750, pca__n_components=100\n",
      "[CV] rf__n_estimators=750, pca__n_components=100, score=0.68454  -  25.1s\n",
      "[CV] rf__n_estimators=100, pca__n_components=200\n",
      "[CV] rf__n_estimators=100, pca__n_components=200, score=0.63925  -  12.3s\n",
      "[CV] rf__n_estimators=100, pca__n_components=200\n",
      "[CV] rf__n_estimators=100, pca__n_components=200, score=0.65011  -  12.2s\n",
      "[CV] rf__n_estimators=100, pca__n_components=200\n",
      "[CV] rf__n_estimators=100, pca__n_components=200, score=0.65142  -  12.6s\n",
      "[CV] rf__n_estimators=100, pca__n_components=200\n",
      "[CV] rf__n_estimators=100, pca__n_components=200, score=0.61163  -  12.5s\n",
      "[CV] rf__n_estimators=100, pca__n_components=200\n",
      "[CV] rf__n_estimators=100, pca__n_components=200, score=0.68454  -  12.6s\n",
      "[CV] rf__n_estimators=250, pca__n_components=200\n",
      "[CV] rf__n_estimators=250, pca__n_components=200, score=0.63925  -  18.2s\n",
      "[CV] rf__n_estimators=250, pca__n_components=200\n",
      "[CV] rf__n_estimators=250, pca__n_components=200, score=0.61982  -  17.6s\n",
      "[CV] rf__n_estimators=250, pca__n_components=200\n",
      "[CV] rf__n_estimators=250, pca__n_components=200, score=0.65142  -  17.4s\n",
      "[CV] rf__n_estimators=250, pca__n_components=200\n",
      "[CV] rf__n_estimators=250, pca__n_components=200, score=0.61163  -  17.7s\n",
      "[CV] rf__n_estimators=250, pca__n_components=200\n",
      "[CV] rf__n_estimators=250, pca__n_components=200, score=0.67413  -  17.9s\n",
      "[CV] rf__n_estimators=500, pca__n_components=200\n",
      "[CV] rf__n_estimators=500, pca__n_components=200, score=0.63925  -  25.9s\n",
      "[CV] rf__n_estimators=500, pca__n_components=200\n",
      "[CV] rf__n_estimators=500, pca__n_components=200, score=0.64023  -  25.7s\n",
      "[CV] rf__n_estimators=500, pca__n_components=200\n",
      "[CV] rf__n_estimators=500, pca__n_components=200, score=0.65142  -  25.5s\n",
      "[CV] rf__n_estimators=500, pca__n_components=200\n",
      "[CV] rf__n_estimators=500, pca__n_components=200, score=0.61163  -  25.7s\n",
      "[CV] rf__n_estimators=500, pca__n_components=200\n",
      "[CV] rf__n_estimators=500, pca__n_components=200, score=0.67413  -  26.0s\n",
      "[CV] rf__n_estimators=750, pca__n_components=200\n",
      "[CV] rf__n_estimators=750, pca__n_components=200, score=0.63925  -  34.6s\n",
      "[CV] rf__n_estimators=750, pca__n_components=200\n",
      "[CV] rf__n_estimators=750, pca__n_components=200, score=0.64023  -  34.7s\n",
      "[CV] rf__n_estimators=750, pca__n_components=200\n",
      "[CV] rf__n_estimators=750, pca__n_components=200, score=0.65142  -  34.0s\n",
      "[CV] rf__n_estimators=750, pca__n_components=200\n",
      "[CV] rf__n_estimators=750, pca__n_components=200, score=0.61163  -  33.6s\n",
      "[CV] rf__n_estimators=750, pca__n_components=200\n",
      "[CV] rf__n_estimators=750, pca__n_components=200, score=0.68454  -  34.3s\n",
      "[CV] rf__n_estimators=100, pca__n_components=300\n",
      "[CV] rf__n_estimators=100, pca__n_components=300, score=0.63925  -  16.2s\n",
      "[CV] rf__n_estimators=100, pca__n_components=300\n",
      "[CV] rf__n_estimators=100, pca__n_components=300, score=0.63003  -  16.4s\n",
      "[CV] rf__n_estimators=100, pca__n_components=300\n",
      "[CV] rf__n_estimators=100, pca__n_components=300, score=0.64122  -  16.9s\n",
      "[CV] rf__n_estimators=100, pca__n_components=300\n",
      "[CV] rf__n_estimators=100, pca__n_components=300, score=0.61196  -  17.2s\n",
      "[CV] rf__n_estimators=100, pca__n_components=300\n",
      "[CV] rf__n_estimators=100, pca__n_components=300, score=0.68454  -  17.3s\n",
      "[CV] rf__n_estimators=250, pca__n_components=300\n",
      "[CV] rf__n_estimators=250, pca__n_components=300, score=0.63925  -  24.3s\n",
      "[CV] rf__n_estimators=250, pca__n_components=300\n",
      "[CV] rf__n_estimators=250, pca__n_components=300, score=0.63003  -  23.5s\n",
      "[CV] rf__n_estimators=250, pca__n_components=300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] rf__n_estimators=250, pca__n_components=300, score=0.65142  -  22.6s\n",
      "[CV] rf__n_estimators=250, pca__n_components=300\n",
      "[CV] rf__n_estimators=250, pca__n_components=300, score=0.61163  -  24.2s\n",
      "[CV] rf__n_estimators=250, pca__n_components=300\n",
      "[CV] rf__n_estimators=250, pca__n_components=300, score=0.68454  -  23.5s\n",
      "[CV] rf__n_estimators=500, pca__n_components=300\n",
      "[CV] rf__n_estimators=500, pca__n_components=300, score=0.63925  -  33.8s\n",
      "[CV] rf__n_estimators=500, pca__n_components=300\n",
      "[CV] rf__n_estimators=500, pca__n_components=300, score=0.61982  -  34.5s\n",
      "[CV] rf__n_estimators=500, pca__n_components=300\n",
      "[CV] rf__n_estimators=500, pca__n_components=300, score=0.65142  -  32.7s\n",
      "[CV] rf__n_estimators=500, pca__n_components=300\n",
      "[CV] rf__n_estimators=500, pca__n_components=300, score=0.61163  -  33.1s\n",
      "[CV] rf__n_estimators=500, pca__n_components=300\n",
      "[CV] rf__n_estimators=500, pca__n_components=300, score=0.68454  -  34.2s\n",
      "[CV] rf__n_estimators=750, pca__n_components=300\n",
      "[CV] rf__n_estimators=750, pca__n_components=300, score=0.63925  -  48.5s\n",
      "[CV] rf__n_estimators=750, pca__n_components=300\n",
      "[CV] rf__n_estimators=750, pca__n_components=300, score=0.63003  -  45.7s\n",
      "[CV] rf__n_estimators=750, pca__n_components=300\n",
      "[CV] rf__n_estimators=750, pca__n_components=300, score=0.65142  -  44.0s\n",
      "[CV] rf__n_estimators=750, pca__n_components=300\n",
      "[CV] rf__n_estimators=750, pca__n_components=300, score=0.61163  -  43.0s\n",
      "[CV] rf__n_estimators=750, pca__n_components=300\n",
      "[CV] rf__n_estimators=750, pca__n_components=300, score=0.68454  -  43.4s\n",
      "Dict{Symbol, Any}(:rf__n_estimators => 100, :pca__n_components => 200)\n"
     ]
    }
   ],
   "source": [
    "# do hyperparameter tuning\n",
    "rocauc = make_scorer(roc_auc_score)\n",
    "xgb_tuned = GridSearchCV(pipe, params_pipe, cv=cv, scoring=rocauc, verbose=3)\n",
    "ScikitLearn.fit!(xgb_tuned, X_train, y_train)\n",
    "println(xgb_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ff156cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808434482223926"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set evaluation\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\")\n",
    "pca = PCA(n_components=200)\n",
    "pipe = Pipeline([(\"pca\", pca), (\"rf\", rf)])\n",
    "model = ScikitLearn.fit!(pipe, X_train, y_train)\n",
    "scores_pos = ScikitLearn.predict_proba(model, X_test)[:,2]\n",
    "roc_auc_score(y_test, scores_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba3787fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models/v2.2/hdc_concat_rf_scores.csv\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save scores for plotting\n",
    "results = DataFrame(labels=y_test, scores=scores_pos)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_concat_rf_scores.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "72e647af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851564585500992\n"
     ]
    }
   ],
   "source": [
    "# doublecheck the other way around!\n",
    "rf = RandomForestClassifier(n_estimators=500, class_weight=\"balanced\")\n",
    "pca = PCA(n_components=300)\n",
    "pipe = Pipeline([(\"pca\", pca), (\"rf\", rf)])\n",
    "auc_scores = []\n",
    "\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=5, shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = features_c[train_indices, :]\n",
    "    y_train = labels[train_indices]\n",
    "    x_test = features_c[test_indices, :]\n",
    "    y_test = labels[test_indices]\n",
    "    \n",
    "    # train the model\n",
    "    model = ScikitLearn.fit!(pipe, x_train, y_train)\n",
    "    \n",
    "    # make predictions and keep the scores\n",
    "    scores_pos = ScikitLearn.predict_proba(model, x_test)[:,2]\n",
    "    push!(auc_scores, roc_auc_score(y_test, scores_pos))\n",
    "end\n",
    "println(mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45824cf2",
   "metadata": {},
   "source": [
    "## 6 - Do PCA and build XGBoost model<a name=\"machinelearningxgb\"></a>\n",
    "\n",
    "in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and CV\n",
    "xgb = xgboost(x_train_r, 500, label=y_train, scale_pos_weight=1/imbalance)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "pipe = Pipeline([(\"pca\", pca), (\"logistic\", logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31680e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance = length(signatures_pos)/length(signatures_neg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee199089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the cross-validation and keep the scores\n",
    "similarities = zeros(Float64, length(loci_embeddings), length(rbp_embeddings))\n",
    "scores_flat = zeros(Float64, length(signatures))\n",
    "\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=10, \n",
    "        shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = signatures_matrix[train_indices, :]\n",
    "    y_train = labels[train_indices]\n",
    "    x_test = signatures_matrix[test_indices, :]\n",
    "    y_test = labels[test_indices]\n",
    "    \n",
    "    # train the model\n",
    "    pca = PCA(n_components=300)\n",
    "    x_train_r = pca.fit_transform(x_train)\n",
    "    model = xgboost(x_train_r, 500, label=y_train, scale_pos_weight=1/imbalance)\n",
    "    \n",
    "    # make predictions and keep the scores\n",
    "    x_test_r = pca.transform(x_test)\n",
    "    scores_pos = XGBoost.predict(model, x_test_r)\n",
    "    \n",
    "    for (i, test_i) in enumerate(test_indices)\n",
    "        pos_i, pos_j = positions[test_i][1], positions[test_i][2]\n",
    "        similarities[pos_i, pos_j] = scores_pos[i]\n",
    "        scores_flat[test_i] = scores_pos[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_from_scores(scores_flat, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205933e6",
   "metadata": {},
   "source": [
    "## X - Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10452d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary: | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for MRR | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for MRR\" begin\n",
    "    @test mean_reciprocal_rank([[0, 0, 0], [0, 1, 0], [1, 0, 0]]) == 0.5\n",
    "    @test mean_reciprocal_rank([[1, 0, 0], [1, 1, 0], [1, 0, 0]]) == 1\n",
    "    A = [0 0 0; 0 1 0; 1 0 0] # Matrix\n",
    "    @test mean_reciprocal_rank(A) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77d726c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:                          | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for constructing relevant matrix | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for constructing relevant matrix\" begin\n",
    "    preds = [0 0 1; 1 1 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == labels # all TPs\n",
    "    preds = [0 0 0; 1 0 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 0; 1 0 0; 0 0 0] # missed TPs\n",
    "    preds = [0 1 0; 1 1 0; 1 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 0; 1 1 0; 0 0 0] # FPs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ecf63855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:                  | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for sorting label matrix | \u001b[32m   2  \u001b[39m\u001b[36m    2\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for sorting label matrix\" begin \n",
    "    rel = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0.5 0.3 1; 1 0.3 0.7; 0.2 0.3 0.3]\n",
    "    @test sort_label_matrix(scores, rel) == [1 0 0; 1 0 1; 0 0 0]\n",
    "    \n",
    "    rel = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [1 0.3 1; 1 0.3 0.7; 0.2 0.3 0.3] # equal score for 0 and 1\n",
    "    @test sort_label_matrix(scores, rel) == [0 1 0; 1 0 1; 0 0 0] # equals will appear in ascending order\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "522f6870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:  | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests pipeline | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests pipeline\" begin\n",
    "    preds = [0 0 1; 0 1 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0 0.2 0.5; 0.3 0.2 0.1; 0.2 0.4 0.3]\n",
    "    relm = construct_relevant_matrix(preds, labels)\n",
    "    sortm = sort_label_matrix(scores, relm)\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 1; 0 1 0; 0 0 0]\n",
    "    @test sort_relevant_matrix(relm, scores) == [1 0 0; 0 1 0; 0 0 0] \n",
    "    @test mean_reciprocal_rank(sortm) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01358f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:         | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests mrr from scores | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests mrr from scores\" begin\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0 0.2 0.5; 0.3 0.5 0.6; 0.2 0.4 0.3]\n",
    "    @test mrr_from_scores(scores, labels, 0.4) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143556f7",
   "metadata": {},
   "source": [
    "## X - Legacy code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee06006",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Here, we perform a 10-fold CV over the loci, just like we do to evaluate the\n",
    "binary classifiers in Python.\n",
    "\"\"\"\n",
    "loci_known = [x for x in range(1, length=length(LociBase)) \n",
    "                if (any(isequal.(interaction_matrix[x,:], 0))) \n",
    "                    || (any(isequal.(interaction_matrix[x,:], 1)))]\n",
    "\n",
    "# shuffle loci\n",
    "loci_shuffle = shuffle(loci_known)\n",
    "\n",
    "# divide into 10 groups\n",
    "group_size = div(length(loci_shuffle), 10) + 1\n",
    "get_groups(x, n) = [x[i:min(i+n-1,length(x))] for i in 1:n:length(x)]\n",
    "loci_groups = get_groups(loci_shuffle, group_size)\n",
    "\n",
    "# loop over groups\n",
    "loci_nr = []; rbp_nr = []; scores = []; scores_pos = []; labels = []\n",
    "for group in loci_groups\n",
    "    # compute signatures for training and testing parts (group = test)\n",
    "    signatures_train_pos = []\n",
    "    signatures_train_neg = []\n",
    "    signatures_test = []\n",
    "    for (i, loci_embedding) in enumerate(loci_embeddings)\n",
    "        for (j, rbp_embedding) in enumerate(rbp_embeddings)\n",
    "            # training pos interaction\n",
    "            if isequal(interaction_matrix[i,j], 1) && i ∉ group\n",
    "                push!(signatures_train_pos, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "            # training neg interaction\n",
    "            elseif isequal(interaction_matrix[i,j], 0) && i ∉ group\n",
    "                push!(signatures_train_neg, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "            # test interaction\n",
    "            elseif isequal(interaction_matrix[i,j], 1) && i in group\n",
    "                push!(signatures_test, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "                push!(loci_nr, i-1) # -1 to cope with indexing python\n",
    "                push!(rbp_nr, j-1)\n",
    "                push!(labels, interaction_matrix[i,j])\n",
    "            elseif isequal(interaction_matrix[i,j], 0) && i in group\n",
    "                push!(signatures_test, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "                push!(loci_nr, i-1)\n",
    "                push!(rbp_nr, j-1)\n",
    "                push!(labels, interaction_matrix[i,j])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # convert signatures\n",
    "    signatures_train_pos = convert(Array{BipolarHDV}, signatures_train_pos)\n",
    "    signatures_train_neg = convert(Array{BipolarHDV}, signatures_train_neg)\n",
    "    signatures_test = convert(Array{BipolarHDV}, signatures_test)\n",
    "    println(\"train size:\", length(signatures_train_pos)+length(signatures_train_neg))\n",
    "    println(\"test size:\", length(signatures_test))\n",
    "    \n",
    "    # aggregate training signatures\n",
    "    signatures_pos_agg = HyperdimensionalComputing.aggregate(signatures_train_pos)\n",
    "    signatures_neg_agg = HyperdimensionalComputing.aggregate(signatures_train_neg)\n",
    "\n",
    "    # compute distance/similarity to test signatures\n",
    "    for test in signatures_test\n",
    "        score_pos_agg = cos_sim(signatures_pos_agg, test)\n",
    "        score_neg_agg = cos_sim(signatures_neg_agg, test)\n",
    "        push!(scores, score_pos_agg/score_neg_agg) # > 1 then pos, < 1 then neg\n",
    "        push!(scores_pos, score_pos_agg)\n",
    "    end\n",
    "end\n",
    "\n",
    "# results pos vs. neg\n",
    "results = DataFrame(locus=loci_nr, rbps=rbp_nr, scores=scores, label=labels)\n",
    "CSV.write(results_dir*\"/results_HDC_grouped10CV_\"*data_suffix*\".csv\", results)\n",
    "\n",
    "# results pos only\n",
    "results = DataFrame(locus=loci_nr, rbps=rbp_nr, scores=scores_pos, label=labels)\n",
    "CSV.write(results_dir*\"/results_HDCpos_grouped10CV_\"*data_suffix*\".csv\", results)\n",
    "\n",
    "# examine scores\n",
    "histogram(scores, xlabel=\"score\", ylabel=\"count\")\n",
    "sum(scores .< 1)/length(scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "226146c2",
   "metadata": {},
   "source": [
    "function construct_relevant_matrix(preds_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function constructs a matrix of relevant predictions\n",
    "    (i.e., true positives) from the prediction matrix and label matrix.\n",
    "    \"\"\"\n",
    "    @assert size(preds_matrix) == size(label_matrix)\n",
    "    relevant_matrix = zeros(Int64, size(preds_matrix)[1], size(preds_matrix)[2])\n",
    "    for i in 1:size(preds_matrix)[1]\n",
    "        for j in 1:size(preds_matrix)[2]\n",
    "            if (preds_matrix[i,j] == label_matrix[i,j]) & (label_matrix[i,j] == 1)\n",
    "                relevant_matrix[i,j] = 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return relevant_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "085a9cd7",
   "metadata": {},
   "source": [
    "function mrr_from_scores_OLD(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    OLD version of the function is a wrapper for the previous functions that computes\n",
    "    the MRR starting from a matrix of (prediction) scores, a threshold above\n",
    "    which to consider an interaction positive and a label matrix.\n",
    "    \"\"\"\n",
    "    # construct the prediction matrix\n",
    "    preds_matrix = convert(Matrix{Int64}, score_matrix .> threshold)\n",
    "\n",
    "    # construct the relevant matrix\n",
    "    replace!(label_matrix, missing => 0)\n",
    "    rel_matrix = construct_relevant_matrix(preds_matrix, label_matrix)\n",
    "\n",
    "    # sort the matrix per row and compute\n",
    "    sorted_matrix = sort_relevant_matrix(rel_matrix, score_matrix)\n",
    "    \n",
    "    return mean_reciprocal_rank(sorted_matrix)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
