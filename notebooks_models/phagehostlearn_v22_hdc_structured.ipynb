{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f577d7df",
   "metadata": {},
   "source": [
    "# PhageHostLearn - v2.2 (Klebsiella)\n",
    "\n",
    "An AI-based Phage-Host interaction predictor framework with K-loci and receptor-binding proteins at its core. This particular PhageHostLearn is for *Klebsiella pneumoniae* related phages. This notebook follows after having ran the PhageHostLearn_processing steps implemented in the accompanying Jupyter notebook.\n",
    "\n",
    "**Architecture of this framework**: \n",
    "- Multi-instance RBP embedding: phages consist of one or more RBPs that are embedded together\n",
    "- Multi-instance K-loci embedding: K-locus consists of multiple proteins that are embedded together\n",
    "- Hyperdimensional vector embeddings for both that are bound to signatures\n",
    "- Signatures that are aggregated to create profiles of the positive class\n",
    "- Unbinding with new loci HDVs on the positive profile to get a proxy for the closest multiRBP HDV\n",
    "- Cosine similarity to compute and rank the closest known multiRBP embeddings\n",
    "\n",
    "**Overview of the notebook**:\n",
    "\n",
    "1. [Defining the necessary functions](#functions)\n",
    "2. [Transform the loci sequences into embeddings](#lociembed) using hyperdimensional vectors\n",
    "3. [Transform the RBP sequences into embeddings](#rbpembed) using hyperdimensional vectors\n",
    "4. [Compute joint features: bind or concat](#joint)\n",
    "5. [Aggregation and cosine similarity](#hdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc1380",
   "metadata": {},
   "source": [
    "## 0 - Libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e3e26c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant PCA. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant RandomForestClassifier. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant roc_auc_score. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "using CSV\n",
    "using Test\n",
    "using JSON\n",
    "using Plots\n",
    "using FASTX\n",
    "using Colors\n",
    "using Random\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using BioAlignments\n",
    "using ProgressMeter\n",
    "using LinearAlgebra\n",
    "using ProgressMeter\n",
    "using BioAlignments\n",
    "using DelimitedFiles\n",
    "using MultivariateStats\n",
    "\n",
    "@sk_import decomposition: PCA\n",
    "@sk_import ensemble: RandomForestClassifier\n",
    "@sk_import metrics: roc_auc_score\n",
    "\n",
    "push!(LOAD_PATH, \"/Users/dimi/Documents/GitHub/HyperdimensionalComputing.jl/src/\")\n",
    "using HyperdimensionalComputing\n",
    "\n",
    "general_dir = \"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/42_DATA/Valencia_data\" # general directory\n",
    "results_dir = \"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models\"\n",
    "data_suffix = \"Valencia\"; # choose a suffix for the created data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cff52b",
   "metadata": {},
   "source": [
    "## 1 - Functions<a name=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015ad564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function file_to_array(file)\n",
    "    \"\"\"\n",
    "    Function that reads a FASTA file and puts its sequences in an array.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    reader = FASTA.Reader(open(file, \"r\"))\n",
    "    for record in reader\n",
    "        seq = FASTA.sequence(record)\n",
    "        push!(sequences, seq)\n",
    "    end\n",
    "    return sequences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc871105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_reciprocal_rank (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mean_reciprocal_rank(queries)\n",
    "    \"\"\"\n",
    "    This function computes the mean reciprocal rank for a given array or\n",
    "    matrix of queries. It deals with relevant vs. non-relevant queries that are\n",
    "    binary. If queries is a matrix, then it will compute the reciprocal ranks over\n",
    "    all rows individually (for each 'query') and then average those.\n",
    "    E.g.:\n",
    "    queries = [[0, 0, 0], [0, 1, 0], [1, 0, 0]]\n",
    "    mean_reciprocal_rank(queries) -> 0.5\n",
    "    \"\"\"\n",
    "    if isa(queries, Matrix)\n",
    "        queries_list = [queries[i,:] for i in 1:size(queries)[1]]\n",
    "        reciprocal_ranks = [sum(query) > 0 ? 1/argmax(query) : 0 for query in queries_list]\n",
    "    else\n",
    "        reciprocal_ranks = [sum(query) > 0 ? 1/argmax(query) : 0 for query in queries]\n",
    "    end\n",
    "    return mean(reciprocal_ranks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3be05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sort_label_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sort_label_matrix(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function sorts the label matrix based on the score matrix.\n",
    "    It does so per row (corresponding to bacteria in our setting).\n",
    "    \n",
    "    WARNING: The sortperm function will rank equal elements by ascending index order. \n",
    "    This potentially can cause an underestimation of performance (MRR), as it can be that \n",
    "    an irrelevant 0 appears earlier and then is place before a relevant 1.\n",
    "    \"\"\"\n",
    "    @assert size(label_matrix) == size(score_matrix)\n",
    "    sorted_matrix = zeros(Int64, size(label_matrix)[1], size(label_matrix)[2])\n",
    "    for i in 1:size(label_matrix)[1] # loop over rows\n",
    "        label_row = label_matrix[i,:]\n",
    "        score_row = score_matrix[i,:]\n",
    "        sorted_row = label_row[sortperm(score_row, rev=true)]\n",
    "        sorted_matrix[i,:] = sorted_row\n",
    "    end\n",
    "    return sorted_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596df09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mrr_from_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mrr_from_scores(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function is a wrapper for the previous functions that computes\n",
    "    the MRR starting from a matrix of (prediction) scores, a threshold above\n",
    "    which to consider an interaction positive and a label matrix.\n",
    "    \"\"\"\n",
    "    # sort the matrix per row and compute\n",
    "    replace!(label_matrix, missing => 0)\n",
    "    sorted_matrix = sort_label_matrix(score_matrix, label_matrix)\n",
    "    \n",
    "    return mean_reciprocal_rank(sorted_matrix)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916c4a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc_from_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function auc_from_scores(scores_flat, labels_flat)\n",
    "    \"\"\"\n",
    "    This function computes the AUC from raw scores returned by ScikitLearn classifiers.\n",
    "    For the AUC, we need the flat versions of scores and labels that don't contain missing \n",
    "    values (if not, this will skew the results).\n",
    "    \n",
    "    Dependencies: MLJ\n",
    "    \"\"\"\n",
    "    c = [\"neg\", \"pos\"]\n",
    "    labels_cat = categorical(c[labels_flat .+ 1])\n",
    "    scores_uni = [UnivariateFinite(categorical([\"neg\", \"pos\"]), [1.0 - p, p]) for p in scores_flat]\n",
    "    AUC = auc(scores_uni, labels_cat)\n",
    "    return AUC\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7123b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_performance (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_performance(score_matrix, label_matrix, scores_flat, labels_flat)\n",
    "    \"\"\"\n",
    "    Wrapper function that computes the two relevant results we want to compare for \n",
    "    our models: the ROC AUC and the MRR.    \n",
    "    \"\"\"\n",
    "    MRR = mrr_from_scores(score_matrix, label_matrix) # compute MRR\n",
    "    AUC = auc_from_scores(scores_flat, labels_flat) # compute AUC\n",
    "    return MRR, AUC\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db0834",
   "metadata": {},
   "source": [
    "## 2 - Computing loci embeddings<a name=\"lociembed\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dcb22",
   "metadata": {},
   "source": [
    "In this section, we define hyperdimensional vectors for the amino-acid alphabet and use these hyperdimensional vectors to construct *hyperdimensional embeddings* for our loci proteins. For the loci proteins, this is a multi-instance setting: multiple proteins will be embedded into hyperdimensional space and then those vectors are aggregated to form one final vector for each locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69da2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "LociBase = JSON.parsefile(general_dir*\"/Locibase\"*data_suffix*\".json\")\n",
    "seros = DataFrame(CSV.File(general_dir*\"/serotypes\"*data_suffix*\".csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb78964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define protein alphabet\n",
    "alphabet = \"GAVLIFPSTYCMKRHWDENQX\"\n",
    "basis = Dict(c=>BipolarHDV() for c in alphabet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "356e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loci embeddings w/ proteins (multi-instance)\n",
    "loci_embeddings = Array{BipolarHDV}(undef, length(LociBase))\n",
    "for (i, (name, proteins)) in enumerate(LociBase)\n",
    "    # bind within one sequence, then aggregate the different sequences\n",
    "    protein_hdvs = [sequence_embedding(string(sequence), basis, 6) for sequence in proteins]\n",
    "    loci_hdv = HyperdimensionalComputing.bind(protein_hdvs)\n",
    "    loci_embeddings[i] = loci_hdv\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573ebc0",
   "metadata": {},
   "source": [
    "## 3 - Computing RBP embeddings<a name=\"rbpembed\"></a>\n",
    "\n",
    "We combine the vectors for each phage's RBP(s), also a multi-instance setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b646f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "RBPbase = DataFrame(CSV.File(general_dir*\"/RBPbase\"*data_suffix*\".csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982319c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rbp embeddings\n",
    "rbp_embeddings = Array{BipolarHDV}(undef, length(unique(RBPbase.phage_ID)))\n",
    "for (i, phageid) in enumerate(unique(RBPbase.phage_ID))\n",
    "    subset = filter(row -> row.phage_ID == phageid, RBPbase)\n",
    "    protein_hdvs = [sequence_embedding(string(sequence), basis, 6) for sequence in subset.protein_sequence]\n",
    "    multirbp_hdv = HyperdimensionalComputing.aggregate(protein_hdvs)\n",
    "    rbp_embeddings[i] = multirbp_hdv\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fa9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46957e",
   "metadata": {},
   "source": [
    "## 4 - Compute joint signatures by binding<a name=\"joint\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f71dbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = DataFrame(CSV.File(general_dir*\"/phage_host_interactions\"*data_suffix*\".csv\"))\n",
    "rename!(IM,:Column1 => :Host)\n",
    "interaction_matrix = Matrix(IM[1:end, 2:end])\n",
    "#loci_names = IM.accession\n",
    "#serotypes = DataFrame(CSV.File(general_dir*\"/serotypes\"*data_suffix*\".csv\"))\n",
    "#rbp_names = names(IM)[2:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cb21946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sigatures for loci x RBP embeddings\n",
    "features_bind = []\n",
    "labels = []\n",
    "loci_groups = []\n",
    "rbp_groups = []\n",
    "for (i, accession) in enumerate(collect(keys(LociBase)))\n",
    "    for (j, phage_id) in enumerate(unique(RBPbase.phage_ID))\n",
    "        subset = filter(row -> row.Host == accession, IM)\n",
    "        interaction = subset[!, phage_id][1]\n",
    "        if isequal(interaction, 1) || isequal(interaction, 0)\n",
    "            signature = HyperdimensionalComputing.bind([loci_embeddings[i], rbp_embeddings[j]])\n",
    "            push!(features_bind, signature)\n",
    "            push!(labels, trunc(Int, interaction))\n",
    "            push!(loci_groups, i)\n",
    "            push!(rbp_groups, j)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01c70737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the signatures in a matrix for sklearn\n",
    "features_b = zeros(Int64, length(features_bind), 10000)\n",
    "for i in range(1, length=length(features_bind))\n",
    "    features_b[i,:] = features_bind[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab7fdd",
   "metadata": {},
   "source": [
    "## 5 - Simple test of structured model\n",
    "\n",
    "Take a random set of loci apart for testing, use the remaining signatures to train a positive profile, then loop over the test loci and unbind from the positive profile, for each unbind, loop over every known multiRBP embedding and compute cosine similarity to rank the multiRBP embeddings for each of the test loci.\n",
    "\n",
    "Remark: perhaps this only works with binary vectors, because * and XOR are inverse of one another (Kanerva), but not sure if that is the same for bipolar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e32c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to compute AUC/MRR for this group: 198\n",
      "unable to compute AUC/MRR for this group: 143\n",
      "unable to compute AUC/MRR for this group: 16\n",
      "unable to compute AUC/MRR for this group: 136\n",
      "unable to compute AUC/MRR for this group: 135\n"
     ]
    }
   ],
   "source": [
    "shuffled_groups = shuffle(unique(loci_groups))\n",
    "train_groups = shuffled_groups[11:end]\n",
    "test_groups = shuffled_groups[1:10];\n",
    "x_train = [features_bind[i] for i in 1:size(features_bind)[1] if loci_groups[i] in train_groups]\n",
    "y_train = [labels[i] for i in 1:size(features_bind)[1] if loci_groups[i] in train_groups]\n",
    "positives = convert(Array{BipolarHDV}, x_train[y_train .== 1])\n",
    "pos_aggregate = HyperdimensionalComputing.aggregate(positives)\n",
    "\n",
    "auc_scores = []\n",
    "ranked_q = []\n",
    "for i in test_groups\n",
    "    locus_hdv = loci_embeddings[i]\n",
    "    unbind = HyperdimensionalComputing.bind([locus_hdv, pos_aggregate])\n",
    "    y_test = labels[loci_groups .== i] # get corresponding labels for this locus test group\n",
    "    if sum(y_test) > 0\n",
    "        x_test_index = rbp_groups[loci_groups .== i] # get corresponding rbp indices for this test group\n",
    "        scores = [(cos_sim(rbp_embeddings[j], unbind)+1)/2 for j in x_test_index]\n",
    "        this_auc = roc_auc_score(y_test, scores)\n",
    "        push!(auc_scores, this_auc)\n",
    "        sorted_query = y_test[sortperm(scores, rev=true)] # sort labels to compute MRR later\n",
    "        push!(ranked_q, sorted_query)\n",
    "    else\n",
    "        println(\"unable to compute AUC/MRR for this group: \", i)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a34dcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426538987688099"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7f5e5",
   "metadata": {},
   "source": [
    "## 6 - K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d46cff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform K-fold cross-validation and keep the scores\n",
    "scores_pos = []\n",
    "kfold_labels = []\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=5, shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = features_bind[train_indices]\n",
    "    y_train = labels[train_indices]\n",
    "    loci_test = loci_groups[test_indices]\n",
    "    rbps_test = rbp_groups[test_indices]\n",
    "    y_test = labels[test_indices]\n",
    "    \n",
    "    # train pos aggregate\n",
    "    positives = convert(Array{BipolarHDV}, x_train[y_train .== 1])\n",
    "    pos_aggregate = HyperdimensionalComputing.aggregate(positives)\n",
    "    \n",
    "    # compute similarities\n",
    "    for (i, loci_index) in enumerate(loci_test)\n",
    "        test_locus = loci_embeddings[loci_index]\n",
    "        test_rbp = rbp_embeddings[rbps_test[i]]\n",
    "        unbind = HyperdimensionalComputing.bind([test_locus, pos_aggregate])\n",
    "        push!(scores_pos, (cos_sim(test_rbp, unbind)+1)/2)\n",
    "        push!(kfold_labels, y_test[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f5e50ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7281339530651976"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(kfold_labels, scores_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e183c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models/v2.2/hdc_structured_scores_locibind.csv\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save scores for plotting\n",
    "results = DataFrame(labels=kfold_labels, scores=scores_pos)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_structured_scores_locibind.csv\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ebfd3",
   "metadata": {},
   "source": [
    "## 7 - Randomized labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9cc8030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41475385638592066\n"
     ]
    }
   ],
   "source": [
    "# perform K-fold cross-validation and keep the scores\n",
    "scores_pos = []\n",
    "kfold_labels = []\n",
    "for (train_indices, test_indices) in CrossValidation.StratifiedKFold(labels, n_folds=5, shuffle=true, random_state=42)\n",
    "    # define training and test data\n",
    "    x_train = features_bind[train_indices]\n",
    "    y_train = labels[train_indices]\n",
    "    loci_test = loci_groups[test_indices]\n",
    "    rbps_test = rbp_groups[test_indices]\n",
    "    y_test = labels[test_indices]\n",
    "    y_shuffled = shuffle(y_train)\n",
    "    \n",
    "    # train pos aggregate\n",
    "    positives = convert(Array{BipolarHDV}, x_train[y_shuffled .== 1])\n",
    "    pos_aggregate = HyperdimensionalComputing.aggregate(positives)\n",
    "    \n",
    "    # compute similarities\n",
    "    for (i, loci_index) in enumerate(loci_test)\n",
    "        test_locus = loci_embeddings[loci_index]\n",
    "        test_rbp = rbp_embeddings[rbps_test[i]]\n",
    "        unbind = HyperdimensionalComputing.bind([test_locus, pos_aggregate])\n",
    "        push!(scores_pos, (cos_sim(test_rbp, unbind)+1)/2)\n",
    "        push!(kfold_labels, y_test[i])\n",
    "    end\n",
    "end\n",
    "println(roc_auc_score(kfold_labels, scores_pos))\n",
    "# save scores for plotting\n",
    "results = DataFrame(labels=kfold_labels, scores=scores_pos)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_structured_scores_random.csv\", results);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8422010",
   "metadata": {},
   "source": [
    "## 7 - LOGOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311c7407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:03\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "auc_scores = []\n",
    "sero_groups = []\n",
    "ranked_q = []\n",
    "p = Progress(200)\n",
    "\n",
    "for item in unique(loci_groups)\n",
    "    # define training and test data\n",
    "    x_train = features_bind[loci_groups .!= item]\n",
    "    y_train = labels[loci_groups .!= item]\n",
    "    x_test = features_bind[loci_groups .== item]\n",
    "    y_test = labels[loci_groups .== item]\n",
    "    rbps_test = rbp_groups[loci_groups .== item]\n",
    "    \n",
    "    # train aggregates\n",
    "    positives = convert(Array{BipolarHDV}, x_train[y_train .== 1])\n",
    "    pos_aggregate = HyperdimensionalComputing.aggregate(positives)\n",
    "    \n",
    "    # compute similarities\n",
    "    test_locus = loci_embeddings[item]\n",
    "    unbind = HyperdimensionalComputing.bind([test_locus, pos_aggregate])\n",
    "    scores_pos = [(cos_sim(rbp_embeddings[rbp_index], unbind)+1)/2 for rbp_index in rbps_test]\n",
    "    try\n",
    "        this_auc = roc_auc_score(y_test, scores_pos)\n",
    "        push!(auc_scores, this_auc)\n",
    "        sorted_query = y_test[sortperm(scores_pos, rev=true)] # sort labels to compute MRR later\n",
    "        push!(ranked_q, sorted_query)\n",
    "        push!(sero_groups, seros.sero[item])\n",
    "    catch\n",
    "    end\n",
    "    \n",
    "    # pbar update\n",
    "    next!(p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f14c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6878209801456135\n",
      "MRR: 0.47245831230339735\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "println(\"AUC: \", mean(auc_scores))\n",
    "println(\"MRR: \", mean_reciprocal_rank(ranked_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "519f4548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/dimi/GoogleDrive/PhD/4_PHAGEHOST_LEARNING/43_RESULTS/models/v2.2/hdc_structured_logocv_results_locibind.csv\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save scores for plotting\n",
    "logo_results = DataFrame(sero=sero_groups, auc_scores=auc_scores, ranked_queries=ranked_q)\n",
    "CSV.write(results_dir*\"/v2.2/hdc_structured_logocv_results_locibind.csv\", logo_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205933e6",
   "metadata": {},
   "source": [
    "## X - Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10452d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary: | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for MRR | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for MRR\" begin\n",
    "    @test mean_reciprocal_rank([[0, 0, 0], [0, 1, 0], [1, 0, 0]]) == 0.5\n",
    "    @test mean_reciprocal_rank([[1, 0, 0], [1, 1, 0], [1, 0, 0]]) == 1\n",
    "    A = [0 0 0; 0 1 0; 1 0 0] # Matrix\n",
    "    @test mean_reciprocal_rank(A) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77d726c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:                          | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for constructing relevant matrix | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for constructing relevant matrix\" begin\n",
    "    preds = [0 0 1; 1 1 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == labels # all TPs\n",
    "    preds = [0 0 0; 1 0 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 0; 1 0 0; 0 0 0] # missed TPs\n",
    "    preds = [0 1 0; 1 1 0; 1 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 0; 1 1 0; 0 0 0] # FPs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ecf63855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:                  | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests for sorting label matrix | \u001b[32m   2  \u001b[39m\u001b[36m    2\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests for sorting label matrix\" begin \n",
    "    rel = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0.5 0.3 1; 1 0.3 0.7; 0.2 0.3 0.3]\n",
    "    @test sort_label_matrix(scores, rel) == [1 0 0; 1 0 1; 0 0 0]\n",
    "    \n",
    "    rel = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [1 0.3 1; 1 0.3 0.7; 0.2 0.3 0.3] # equal score for 0 and 1\n",
    "    @test sort_label_matrix(scores, rel) == [0 1 0; 1 0 1; 0 0 0] # equals will appear in ascending order\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "522f6870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:  | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests pipeline | \u001b[32m   3  \u001b[39m\u001b[36m    3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests pipeline\" begin\n",
    "    preds = [0 0 1; 0 1 0; 0 0 0]\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0 0.2 0.5; 0.3 0.2 0.1; 0.2 0.4 0.3]\n",
    "    relm = construct_relevant_matrix(preds, labels)\n",
    "    sortm = sort_label_matrix(scores, relm)\n",
    "    @test construct_relevant_matrix(preds, labels) == [0 0 1; 0 1 0; 0 0 0]\n",
    "    @test sort_relevant_matrix(relm, scores) == [1 0 0; 0 1 0; 0 0 0] \n",
    "    @test mean_reciprocal_rank(sortm) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01358f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:         | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "tests mrr from scores | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@testset \"tests mrr from scores\" begin\n",
    "    labels = [0 0 1; 1 1 0; 0 0 0]\n",
    "    scores = [0 0.2 0.5; 0.3 0.5 0.6; 0.2 0.4 0.3]\n",
    "    @test mrr_from_scores(scores, labels, 0.4) == 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143556f7",
   "metadata": {},
   "source": [
    "## X - Legacy code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee06006",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Here, we perform a 10-fold CV over the loci, just like we do to evaluate the\n",
    "binary classifiers in Python.\n",
    "\"\"\"\n",
    "loci_known = [x for x in range(1, length=length(LociBase)) \n",
    "                if (any(isequal.(interaction_matrix[x,:], 0))) \n",
    "                    || (any(isequal.(interaction_matrix[x,:], 1)))]\n",
    "\n",
    "# shuffle loci\n",
    "loci_shuffle = shuffle(loci_known)\n",
    "\n",
    "# divide into 10 groups\n",
    "group_size = div(length(loci_shuffle), 10) + 1\n",
    "get_groups(x, n) = [x[i:min(i+n-1,length(x))] for i in 1:n:length(x)]\n",
    "loci_groups = get_groups(loci_shuffle, group_size)\n",
    "\n",
    "# loop over groups\n",
    "loci_nr = []; rbp_nr = []; scores = []; scores_pos = []; labels = []\n",
    "for group in loci_groups\n",
    "    # compute signatures for training and testing parts (group = test)\n",
    "    signatures_train_pos = []\n",
    "    signatures_train_neg = []\n",
    "    signatures_test = []\n",
    "    for (i, loci_embedding) in enumerate(loci_embeddings)\n",
    "        for (j, rbp_embedding) in enumerate(rbp_embeddings)\n",
    "            # training pos interaction\n",
    "            if isequal(interaction_matrix[i,j], 1) && i ∉ group\n",
    "                push!(signatures_train_pos, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "            # training neg interaction\n",
    "            elseif isequal(interaction_matrix[i,j], 0) && i ∉ group\n",
    "                push!(signatures_train_neg, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "            # test interaction\n",
    "            elseif isequal(interaction_matrix[i,j], 1) && i in group\n",
    "                push!(signatures_test, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "                push!(loci_nr, i-1) # -1 to cope with indexing python\n",
    "                push!(rbp_nr, j-1)\n",
    "                push!(labels, interaction_matrix[i,j])\n",
    "            elseif isequal(interaction_matrix[i,j], 0) && i in group\n",
    "                push!(signatures_test, HyperdimensionalComputing.bind([loci_embedding, rbp_embedding]))\n",
    "                push!(loci_nr, i-1)\n",
    "                push!(rbp_nr, j-1)\n",
    "                push!(labels, interaction_matrix[i,j])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # convert signatures\n",
    "    signatures_train_pos = convert(Array{BipolarHDV}, signatures_train_pos)\n",
    "    signatures_train_neg = convert(Array{BipolarHDV}, signatures_train_neg)\n",
    "    signatures_test = convert(Array{BipolarHDV}, signatures_test)\n",
    "    println(\"train size:\", length(signatures_train_pos)+length(signatures_train_neg))\n",
    "    println(\"test size:\", length(signatures_test))\n",
    "    \n",
    "    # aggregate training signatures\n",
    "    signatures_pos_agg = HyperdimensionalComputing.aggregate(signatures_train_pos)\n",
    "    signatures_neg_agg = HyperdimensionalComputing.aggregate(signatures_train_neg)\n",
    "\n",
    "    # compute distance/similarity to test signatures\n",
    "    for test in signatures_test\n",
    "        score_pos_agg = cos_sim(signatures_pos_agg, test)\n",
    "        score_neg_agg = cos_sim(signatures_neg_agg, test)\n",
    "        push!(scores, score_pos_agg/score_neg_agg) # > 1 then pos, < 1 then neg\n",
    "        push!(scores_pos, score_pos_agg)\n",
    "    end\n",
    "end\n",
    "\n",
    "# results pos vs. neg\n",
    "results = DataFrame(locus=loci_nr, rbps=rbp_nr, scores=scores, label=labels)\n",
    "CSV.write(results_dir*\"/results_HDC_grouped10CV_\"*data_suffix*\".csv\", results)\n",
    "\n",
    "# results pos only\n",
    "results = DataFrame(locus=loci_nr, rbps=rbp_nr, scores=scores_pos, label=labels)\n",
    "CSV.write(results_dir*\"/results_HDCpos_grouped10CV_\"*data_suffix*\".csv\", results)\n",
    "\n",
    "# examine scores\n",
    "histogram(scores, xlabel=\"score\", ylabel=\"count\")\n",
    "sum(scores .< 1)/length(scores)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "226146c2",
   "metadata": {},
   "source": [
    "function construct_relevant_matrix(preds_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    This function constructs a matrix of relevant predictions\n",
    "    (i.e., true positives) from the prediction matrix and label matrix.\n",
    "    \"\"\"\n",
    "    @assert size(preds_matrix) == size(label_matrix)\n",
    "    relevant_matrix = zeros(Int64, size(preds_matrix)[1], size(preds_matrix)[2])\n",
    "    for i in 1:size(preds_matrix)[1]\n",
    "        for j in 1:size(preds_matrix)[2]\n",
    "            if (preds_matrix[i,j] == label_matrix[i,j]) & (label_matrix[i,j] == 1)\n",
    "                relevant_matrix[i,j] = 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return relevant_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "085a9cd7",
   "metadata": {},
   "source": [
    "function mrr_from_scores_OLD(score_matrix, label_matrix)\n",
    "    \"\"\"\n",
    "    OLD version of the function is a wrapper for the previous functions that computes\n",
    "    the MRR starting from a matrix of (prediction) scores, a threshold above\n",
    "    which to consider an interaction positive and a label matrix.\n",
    "    \"\"\"\n",
    "    # construct the prediction matrix\n",
    "    preds_matrix = convert(Matrix{Int64}, score_matrix .> threshold)\n",
    "\n",
    "    # construct the relevant matrix\n",
    "    replace!(label_matrix, missing => 0)\n",
    "    rel_matrix = construct_relevant_matrix(preds_matrix, label_matrix)\n",
    "\n",
    "    # sort the matrix per row and compute\n",
    "    sorted_matrix = sort_relevant_matrix(rel_matrix, score_matrix)\n",
    "    \n",
    "    return mean_reciprocal_rank(sorted_matrix)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
